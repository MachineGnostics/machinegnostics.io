{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Machine Gnostics","text":"<p>Welcome to Machine Gnostics, an innovative Python library designed to implement the principles of Mathematical Gnostics for robust data analysis, modeling, and inference. Unlike traditional statistical approaches that depend heavily on probabilistic assumptions, Machine Gnostics harnesses deterministic algebraic and geometric structures. This unique foundation enables the library to deliver exceptional resilience against outliers, noise, and corrupted data, making it a powerful tool for challenging real-world scenarios.</p> <p>Machine Gnostics is an open-source initiative that seeks to redefine the mathematical underpinnings of machine learning. While most conventional ML libraries are grounded in probabilistic and statistical frameworks, Machine Gnostics explores alternative paradigms\u2014drawing from deterministic algebra, information theory, and geometric methods. This approach opens new avenues for building robust, interpretable, and reliable analysis tools that can withstand the limitations of traditional models.</p> <p>Machine Gnostics</p> <p>As a pioneering project, Machine Gnostics invites users to adopt a fresh perspective and develop a new understanding of machine learning. The library is currently in its infancy, and as such, some features may require refinement and fixes. We are actively working to expand its capabilities, with new models and methods planned for the near future. Community support and collaboration are essential to realizing Machine Gnostics\u2019 full potential. Together, let\u2019s build a new AI grounded in a rational and resilient paradigm.</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>Machine Gnostics offers a comprehensive suite of tools for robust analysis:</p> <ul> <li>Robust Regression Models \u2013 Polynomial regression models with gnostic-based weighting for optimal resilience to outliers</li> <li>Gnostic Metrics \u2013 Alternative evaluation metrics that provide more reliable performance assessment in the presence of corrupted data</li> <li>Mathematical Gnostics Calculations \u2013 Core implementations of gnostic statistics including robust measures of central tendency, dispersion, and correlation</li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udee1\ufe0f Exceptional Outlier Resistance \u2013 Automatically detects and downweights anomalous observations without manual intervention</li> <li>\ud83d\udd0d Information-Theoretic Foundation \u2013 Based on rigorous mathematical principles rather than probabilistic assumptions</li> <li>\ud83d\udd27 Drop-in Replacements \u2013 Use gnostic alternatives to common statistical measures like mean, median, correlation</li> <li>\ud83d\udcca MLflow Integration \u2013 Seamless model tracking, versioning, and deployment</li> <li>\ud83e\uddea Scientifically Validated \u2013 Tested on real-world problems across multiple domains including thermodynamics, materials science, and engineering</li> </ul>"},{"location":"#references","title":"References","text":""},{"location":"#license-gnu-v30","title":"License GNU v3.0","text":""},{"location":"contact/","title":"Contact","text":"<p>If you have any questions, suggestions, or issues related to Machine Gnostics, feel free to reach out. We welcome feedback from the community and are happy to assist you.</p> <p>Contact Person Dr. Nirmal Parmar \ud83d\udce7 machinegnostics@gmail.com</p> <p>Support</p> <p>We appreciate your interest in Machine Gnostics and look forward to collaborating with researchers, developers, and practitioners passionate about robust and interpretable machine learning.</p> <p>For issues or feature requests, please consider opening a ticket on our GitHub repository.</p>"},{"location":"installation/","title":"Installation Guide","text":"<p>Machine Gnostics is distributed as a standard Python package and is designed for easy installation and integration into your data science workflow. The library has been tested on macOS with Python 3.11 and is fully compatible with standard data science libraries such as NumPy, pandas, and SciPy.</p>"},{"location":"installation/#1-create-a-python-virtual-environment","title":"1. Create a Python Virtual Environment","text":"<p>It is best practice to use a virtual environment to manage your project dependencies and avoid conflicts with other Python packages.</p> <pre><code># Create a new virtual environment named 'machine-gnostics-env'\npython3 -m venv machinegnostics-env\n\n# Activate the environment (macOS/Linux)\nsource machinegnostics-env/bin/activate\n\n# (On Windows, use: machinegnostics-env\\Scripts\\activate)\n</code></pre>"},{"location":"installation/#2-install-machine-gnostics","title":"2. Install Machine Gnostics","text":"<p>Install the Machine Gnostics library using pip:</p> <pre><code># main installation\npip install machinegnostics\n\n# temporary test installation\npip install -i https://test.pypi.org/simple/ machinegnostics\n</code></pre> <p>This command will install Machine Gnostics and automatically resolve its dependencies.</p>"},{"location":"installation/#3-verify-installation","title":"3. Verify Installation","text":"<p>You can verify that Machine Gnostics and its dependencies are installed correctly by importing them in a Python session:</p> <pre><code>import machinegnostics\n\nprint(\"imported successfully!\")\n</code></pre>"},{"location":"installation/#4-quick-usage-example","title":"4. Quick Usage Example","text":"<p>Machine Gnostics is designed to be as simple to use as other machine learning libraries. You can call its functions and classes directly after installation.</p> <pre><code>import numpy as np\nfrom machinegnostics.models.regression import LinearRegressor\n\n# Example data\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2, 4, 6, 8])\n\n# Create and fit a robust polynomial regression model\nmodel = LinearRegressor()\nmodel.fit(X, y)\n\n# Make predictions\ny_pred = model.predict(X)\n\nprint(\"Predictions:\", y_pred)\n</code></pre>"},{"location":"installation/#5-platform-and-environment","title":"5. Platform and Environment","text":"<ul> <li>Operating System: Tested on macOS (Apple Silicon and Intel)</li> <li>Python Version: 3.11 recommended</li> <li>Dependencies: Compatible with NumPy, pandas, SciPy, and other standard data science libraries</li> </ul>"},{"location":"installation/#6-troubleshooting","title":"6. Troubleshooting","text":"<ul> <li>Ensure your virtual environment is activated before installing or running Machine Gnostics.</li> <li>If you encounter issues, try upgrading pip:</li> </ul> <pre><code>pip install --upgrade pip\n</code></pre> <p>Help</p> <ul> <li>For further help, consult us or open an issue on the GitHub repository.</li> </ul> <p>Machine Gnostics is designed for simplicity and reliability, making robust machine learning accessible for all Python users.</p>"},{"location":"metrics/accuracy/","title":"accuracy_score: Classification Accuracy Metric","text":"<p>The <code>accuracy_score</code> function computes the accuracy of classification models by comparing predicted labels to true labels. It is a fundamental metric for evaluating the performance of classifiers in binary and multiclass settings.</p>"},{"location":"metrics/accuracy/#overview","title":"Overview","text":"<p>Accuracy is defined as the proportion of correct predictions among the total number of cases examined. It is a simple yet powerful metric for assessing how well a model is performing, especially when the classes are balanced.</p>"},{"location":"metrics/accuracy/#parameters","title":"Parameters","text":"Parameter Type Description <code>y_true</code> array-like or pandas Series Ground truth (correct) target values. Shape: (n_samples,) <code>y_pred</code> array-like or pandas Series Estimated target values as returned by a classifier. Shape: (n_samples,) <ul> <li>Both <code>y_true</code> and <code>y_pred</code> can be numpy arrays, lists, or pandas Series.  </li> <li>If a pandas DataFrame is passed, a <code>ValueError</code> is raised (select a column instead).</li> </ul>"},{"location":"metrics/accuracy/#returns","title":"Returns","text":"<ul> <li>accuracy: <code>float</code>   The accuracy score as a float in the range [0, 1].</li> </ul>"},{"location":"metrics/accuracy/#raises","title":"Raises","text":"<ul> <li>ValueError </li> <li>If <code>y_true</code> or <code>y_pred</code> is a pandas DataFrame (must select a column).</li> <li>If the shapes of <code>y_true</code> and <code>y_pred</code> do not match.</li> </ul>"},{"location":"metrics/accuracy/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import accuracy_score\n\n# Example 1: Using lists\ny_true = [0, 1, 2, 2, 0]\ny_pred = [0, 0, 2, 2, 0]\nprint(accuracy_score(y_true, y_pred))  # Output: 0.8\n\n# Example 2: Using pandas Series\nimport pandas as pd\ndf = pd.DataFrame({'true': [1, 0, 1], 'pred': [1, 1, 1]})\nprint(accuracy_score(df['true'], df['pred']))  # Output: 0.6666666666666666\n</code></pre>"},{"location":"metrics/accuracy/#notes","title":"Notes","text":"<ul> <li>The function supports input as numpy arrays, lists, or pandas Series.</li> <li>If you pass a pandas DataFrame, you must select a column (e.g., <code>df['col']</code>), not the whole DataFrame.</li> <li>The accuracy metric is most informative when the dataset is balanced. For imbalanced datasets, consider additional metrics such as precision, recall, or F1 score.</li> </ul>"},{"location":"metrics/classification_report/","title":"classification_report: Classification Metrics Summary","text":"<p>The <code>classification_report</code> function generates a comprehensive summary of key classification metrics\u2014precision, recall, F1 score, and support\u2014for each class in your dataset. It supports both string and dictionary output formats, making it suitable for both human-readable reports and programmatic analysis.</p>"},{"location":"metrics/classification_report/#overview","title":"Overview","text":"<p>This function provides a detailed breakdown of classifier performance for each class, including:</p> <ul> <li>Precision: Proportion of positive identifications that were actually correct.</li> <li>Recall: Proportion of actual positives that were correctly identified.</li> <li>F1 Score: Harmonic mean of precision and recall.</li> <li>Support: Number of true instances for each class.</li> </ul> <p>It also computes weighted averages across all classes.</p>"},{"location":"metrics/classification_report/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y_true</code> array-like or pandas Series \u2014 Ground truth (correct) target values. Shape: (n_samples,) <code>y_pred</code> array-like or pandas Series \u2014 Estimated target values as returned by a classifier. Shape: (n_samples,) <code>labels</code> array-like or None None List of labels to include in the report. If None, uses sorted unique labels from y_true and y_pred. <code>target_names</code> list of str or None None Optional display names matching the labels (same order). <code>digits</code> int 2 Number of digits for formatting output. <code>output_dict</code> bool False If True, return output as a dict. If False, return as a formatted string. <code>zero_division</code> {0, 1, 'warn'} 0 Value to return when there is a zero division (no predicted samples for a class)."},{"location":"metrics/classification_report/#returns","title":"Returns","text":"<ul> <li>report: <code>str</code> or <code>dict</code>   Text summary or dictionary of the precision, recall, F1 score, and support for each class.</li> </ul>"},{"location":"metrics/classification_report/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import classification_report\n\ny_true = [0, 1, 2, 2, 0]\ny_pred = [0, 0, 2, 2, 0]\n\n# String report\nprint(classification_report(y_true, y_pred))\n\n# Dictionary report\nreport_dict = classification_report(y_true, y_pred, output_dict=True)\nprint(report_dict)\n</code></pre>"},{"location":"metrics/classification_report/#output-example","title":"Output Example","text":"<p>String Output:</p> <pre><code>Class             Precision    Recall   F1-score    Support\n==========================================================\n0                    1.00      0.50      0.67          2\n1                    0.00      0.00      0.00          1\n2                    1.00      1.00      1.00          2\n==========================================================\nAvg/Total            0.80      0.60      0.67          5\n</code></pre> <p>Dictionary Output:</p> <pre><code>{\n  '0': {'precision': 1.0, 'recall': 0.5, 'f1-score': 0.67, 'support': 2},\n  '1': {'precision': 0.0, 'recall': 0.0, 'f1-score': 0.0, 'support': 1},\n  '2': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 2},\n  'avg/total': {'precision': 0.8, 'recall': 0.6, 'f1-score': 0.67, 'support': 5}\n}\n</code></pre>"},{"location":"metrics/classification_report/#notes","title":"Notes","text":"<ul> <li>The function uses <code>precision_score</code>, <code>recall_score</code>, and <code>f1_score</code> from the Machine Gnostics metrics module for consistency.</li> <li>If <code>target_names</code> is provided, its length must match the number of labels.</li> <li>For imbalanced datasets, the weighted average provides a more informative summary than the unweighted mean.</li> <li>The <code>zero_division</code> parameter controls the behavior when a class has no predicted samples.</li> </ul>"},{"location":"metrics/divI/","title":"divI: Divergence Information (DivI) Metric","text":"<p>The <code>divI</code> function computes the Divergence Information (DivI) metric, a robust measure for evaluating the divergence between observed data and model predictions. This metric is based on gnostic characteristics and is particularly useful for assessing the quality of model fits, especially in the presence of noise or outliers.</p>"},{"location":"metrics/divI/#overview","title":"Overview","text":"<p>Divergence Information (DivI) quantifies how much the information content of the predicted values diverges from that of the true values. Unlike classical divergence measures, DivI leverages gnostic algebra, making it robust to irregularities and non-Gaussian data.</p> <p>Mathematically, DivI is defined as:</p> \\[ \\text{DivI} = \\frac{1}{N} \\sum_{i=1}^N \\frac{I(y_i)}{I(\\hat{y}_i)} \\] <p>where:</p> <ul> <li>\\(I(y_i)\\) is the E-information of the observed value \\(y_i\\),</li> <li>\\(I(\\hat{y}_i)\\) is the E-information of the fitted value \\(\\hat{y}_i\\),</li> <li>\\(N\\) is the number of data points.</li> </ul> <p>DivI compares the information content of the dependent variable and its fit. The better the fit, the closer DivI is to 1. If the fit is highly uncertain or poor, DivI decreases.</p>"},{"location":"metrics/divI/#interpretation","title":"Interpretation","text":"<ul> <li>Higher DivI: Indicates that the fitted values retain more of the information content of the observed data, suggesting a better model fit.</li> <li>Lower DivI: Indicates greater divergence between the distributions of the observed and fitted values, suggesting a poorer fit or higher uncertainty in the model.</li> </ul> <p>DivI is particularly useful in robust model evaluation, as it is less sensitive to outliers and non-normal data distributions.</p>"},{"location":"metrics/divI/#parameters","title":"Parameters","text":"Parameter Type Description <code>y</code> np.ndarray Observed data (ground truth). 1D array of numerical values. <code>y_fit</code> np.ndarray Fitted data (model predictions). 1D array, same shape as <code>y</code>."},{"location":"metrics/divI/#returns","title":"Returns","text":"<ul> <li>float   The computed Divergence Information (DivI) value.</li> </ul>"},{"location":"metrics/divI/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y</code> and <code>y_fit</code> do not have the same shape.</li> <li>If <code>y</code> or <code>y_fit</code> are not 1D arrays.</li> </ul>"},{"location":"metrics/divI/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.metrics import divI\n\ny = np.array([1.0, 2.0, 3.0, 4.0])\ny_fit = np.array([1.1, 1.9, 3.2, 3.8])\nresult = divI(y, y_fit)\nprint(result)  # Output: 0.06666666666666667\n</code></pre>"},{"location":"metrics/divI/#notes","title":"Notes","text":"<ul> <li>DivI is calculated using gnostic characteristics, providing a robust way to measure divergence between distributions.</li> <li>The metric is especially useful for model evaluation in real-world scenarios where data may be noisy or contain outliers.</li> <li>In the context of model evaluation, DivI is often used alongside other criteria such as Robust R-squared (RobR2) and the Geometric Mean of Multiplicative Fitting Errors (GMMFE) to provide a comprehensive assessment of model performance.</li> </ul>"},{"location":"metrics/evalmet/","title":"evalMet: Composite Evaluation Metric","text":"<p>The <code>evalMet</code> function computes the Evaluation Metric (EvalMet), a composite score that combines three robust criteria\u2014Robust R-squared (RobR2), Geometric Mean of Model Fit Error (GMMFE), and Divergence Information (DivI)\u2014to provide a comprehensive assessment of model performance.</p>"},{"location":"metrics/evalmet/#overview","title":"Overview","text":"<p>EvalMet is designed to quantify the overall quality of a model fit by integrating three complementary metrics:</p> <ul> <li>RobR2: Measures the proportion of variance explained by the model, robust to outliers.</li> <li>GMMFE: Captures the average multiplicative fitting error on a logarithmic scale.</li> <li>DivI: Quantifies the divergence in information content between the observed data and the model fit.</li> </ul> <p>The combined metric is calculated as:</p> \\[ \\text{EvalMet} = \\frac{\\text{RobR2}}{\\text{GMMFE} \\cdot \\text{DivI}} \\] <p>A higher EvalMet value indicates a better model fit, balancing explained variance, error magnitude, and information divergence.</p>"},{"location":"metrics/evalmet/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y</code> np.ndarray \u2014 Observed data (ground truth). 1D array of numerical values. <code>y_fit</code> np.ndarray \u2014 Fitted data (model predictions). 1D array, same shape as <code>y</code>. <code>w</code> np.ndarray None Optional weights for data points. 1D array, same shape as <code>y</code>. If not provided, equal weights are used."},{"location":"metrics/evalmet/#returns","title":"Returns","text":"<ul> <li>float   The computed Evaluation Metric (EvalMet) value.</li> </ul>"},{"location":"metrics/evalmet/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y</code> and <code>y_fit</code> do not have the same shape.</li> <li>If <code>w</code> is provided and does not have the same shape as <code>y</code>.</li> <li>If <code>y</code> or <code>y_fit</code> are not 1D arrays.</li> </ul>"},{"location":"metrics/evalmet/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.metrics import evalMet\n\ny = np.array([1.0, 2.0, 3.0, 4.0])\ny_fit = np.array([1.1, 1.9, 3.2, 3.8])\nresult = evalMet(y, y_fit)\nprint(result)\n</code></pre>"},{"location":"metrics/evalmet/#notes","title":"Notes","text":"<ul> <li>EvalMet is most informative when used to compare multiple models or methods on the same dataset.</li> <li>The metric is robust to outliers and non-Gaussian data due to its use of gnostic algebra.</li> <li>EvalMet is especially useful in benchmarking and model selection scenarios, as it integrates multiple aspects of fit quality into a single score.</li> </ul>"},{"location":"metrics/f1_score/","title":"f1_score: Classification F1 Score Metric","text":"<p>The <code>f1_score</code> function computes the F1 score for classification models, supporting both binary and multiclass settings. The F1 score is the harmonic mean of precision and recall, providing a balanced measure that is especially useful when classes are imbalanced.</p>"},{"location":"metrics/f1_score/#overview","title":"Overview","text":"<p>The F1 score combines precision and recall into a single metric by taking their harmonic mean.</p> <p>This metric is particularly important when you want to balance the trade-off between precision and recall, such as in information retrieval, medical diagnosis, and fraud detection.</p>"},{"location":"metrics/f1_score/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y_true</code> array-like or pandas Series \u2014 Ground truth (correct) target values. Shape: (n_samples,) <code>y_pred</code> array-like or pandas Series \u2014 Estimated target values as returned by a classifier. Shape: (n_samples,) <code>average</code> {'binary', 'micro', 'macro', 'weighted', None} 'binary' Determines the type of averaging performed on the data. See below for details. <code>labels</code> array-like or None None List of labels to include. If None, uses sorted unique labels from y_true and y_pred."},{"location":"metrics/f1_score/#averaging-options","title":"Averaging Options","text":"<ul> <li>'binary': Only report results for the positive class (default for binary classification).</li> <li>'micro': Calculate metrics globally by counting the total true positives, false negatives, and false positives.</li> <li>'macro': Calculate metrics for each label, and find their unweighted mean.</li> <li>'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label).</li> <li>None: Return the F1 score for each class as an array.</li> </ul>"},{"location":"metrics/f1_score/#returns","title":"Returns","text":"<ul> <li>f1: <code>float</code> or <code>array of floats</code>   F1 score(s). Returns a float if <code>average</code> is not None, otherwise returns an array of F1 values for each class.</li> </ul>"},{"location":"metrics/f1_score/#raises","title":"Raises","text":"<ul> <li>ValueError </li> <li>If <code>y_true</code> or <code>y_pred</code> is a pandas DataFrame (must select a column).</li> <li>If the shapes of <code>y_true</code> and <code>y_pred</code> do not match.</li> <li>If <code>average='binary'</code> but the problem is not binary classification.</li> <li>If <code>average</code> is not a recognized option.</li> </ul>"},{"location":"metrics/f1_score/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import f1_score\n\n# Example 1: Macro-averaged F1 for multiclass\ny_true = [0, 1, 2, 2, 0]\ny_pred = [0, 0, 2, 2, 0]\nprint(f1_score(y_true, y_pred, average='macro'))  # Output: 0.7777777777777777\n\n# Example 2: Binary F1 with pandas Series\nimport pandas as pd\ndf = pd.DataFrame({'true': [1, 0, 1], 'pred': [1, 1, 1]})\nprint(f1_score(df['true'], df['pred'], average='binary'))  # Output: 0.8\n</code></pre>"},{"location":"metrics/f1_score/#notes","title":"Notes","text":"<ul> <li>The function supports input as numpy arrays, lists, or pandas Series.</li> <li>If you pass a pandas DataFrame, you must select a column (e.g., <code>df['col']</code>), not the whole DataFrame.</li> <li>For binary classification, by convention, the second label is treated as the positive class.</li> <li>For imbalanced datasets, consider using <code>average='weighted'</code> to account for class support.</li> </ul>"},{"location":"metrics/g_correlation/","title":"gcorrelation: Gnostic Correlation Metric","text":"<p>The <code>gcorrelation</code> function computes the Gnostic correlation coefficient between two data samples using robust irrelevance-based weighting. This metric provides a robust alternative to the classical Pearson correlation, making it less sensitive to outliers and non-normal data distributions.</p>"},{"location":"metrics/g_correlation/#overview","title":"Overview","text":"<p>Gnostic correlation leverages irrelevance functions to construct robust weights for each data point, following the gnostic framework described by Kovanic &amp; Humber (2015). This approach allows for a more reliable measure of association between variables, especially in the presence of noise or outliers.</p> <ul> <li>Robust to outliers: Uses irrelevance-based weighting.</li> <li>No normality assumption: Works well with non-Gaussian data.</li> <li>Flexible: Supports both 1D and 2D data (column-wise correlation).</li> </ul>"},{"location":"metrics/g_correlation/#parameters","title":"Parameters","text":"Parameter Type Description <code>data_1</code> np.ndarray, pandas Series, or DataFrame First data sample (1D or 2D). Each column is treated as a variable. <code>data_2</code> np.ndarray, pandas Series, or DataFrame Second data sample (must have same number of rows as <code>data_1</code>)."},{"location":"metrics/g_correlation/#returns","title":"Returns","text":"<ul> <li>float, np.ndarray, or pandas.DataFrame   The calculated Gnostic correlation coefficient(s):</li> <li>If both inputs are 1D: returns a float.</li> <li>If either input is 2D: returns a correlation matrix (np.ndarray or pandas DataFrame if input was pandas).</li> </ul>"},{"location":"metrics/g_correlation/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If input arrays have different lengths.</li> <li>If inputs are empty or not numpy arrays/pandas Series/DataFrame.</li> <li>If input shapes are incompatible.</li> </ul>"},{"location":"metrics/g_correlation/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.metrics import gcorrelation\n\n# Example 1: 1D arrays (robust analog of Pearson correlation)\nx = np.array([1.0, 2.0, 3.0, 4.0, 5.0])\ny = np.array([0.9, 2.1, 2.9, 4.2, 4.8])\ngcor = gcorrelation(x, y)\nprint(f\"Estimation correlation: {gcor:.3f}\")  # Output: Estimation correlation: 0.999\n\n# Example 2: DataFrames (column-wise correlation matrix)\nimport pandas as pd\ndf1 = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\ndf2 = pd.DataFrame({'c': [1, 2, 1], 'd': [6, 5, 4]})\ncorr_matrix = gcorrelation(df1, df2)\nprint(corr_matrix)\n</code></pre>"},{"location":"metrics/g_correlation/#notes","title":"Notes","text":"<ul> <li>The location parameter is set by the mean (can be replaced by G-median for higher robustness).</li> <li>The geometric mean of the weights is used as the \"best\" weighting vector.</li> <li>For 2D arrays or DataFrames, the function computes the correlation for each pair of columns.</li> <li>The output is a DataFrame with appropriate column and index names if the input was pandas.</li> </ul>"},{"location":"metrics/g_relevance/","title":"hc: Gnostic Characteristics (Hc) Metric","text":"<p>The <code>hc</code> function computes the Gnostic Characteristics (Hc) metric, a robust measure for evaluating the relevance or irrelevance between true and predicted values. Here, <code>c</code> denotes case of <code>i</code>- Estimation or <code>j</code> - Quantification condition.  This metric is part of the Machine Gnostics framework and is particularly useful for assessing model performance in the presence of noise or outliers.</p>"},{"location":"metrics/g_relevance/#overview","title":"Overview","text":"<p>The Hc metric quantifies the relationship between predicted and true values using gnostic algebra. It can be used in two modes:</p> <ul> <li>Relevance (<code>case='i'</code>): Measures how relevant the predictions are to the true values as per mathematical gnostics.</li> <li>Irrelevance (<code>case='j'</code>): Measures how irrelevant the predictions are to the true values as per mathematical gnostics.</li> </ul> <p>The metric is calculated as the normalized sum of squared gnostic characteristics, providing a robust alternative to classical error metrics.</p>"},{"location":"metrics/g_relevance/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y_true</code> array-like \u2014 True (ground truth) values. <code>y_pred</code> array-like \u2014 Predicted values from the model. <code>case</code> str 'i' Calculation mode:<code>'i'</code> for relevance, <code>'j'</code> for irrelevance."},{"location":"metrics/g_relevance/#returns","title":"Returns","text":"<ul> <li>float   The calculated Hc value (normalized sum of squared gnostic characteristics).</li> </ul>"},{"location":"metrics/g_relevance/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y_true</code> and <code>y_pred</code> have different lengths.</li> <li>If <code>case</code> is not <code>'i'</code> or <code>'j'</code>.</li> </ul>"},{"location":"metrics/g_relevance/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import hc\n\ny_true = [1, 2, 3]\ny_pred = [1, 2, 3]\n\n# Calculate gnostic relevance\nhc_value = hc(y_true, y_pred, case='i')\nprint(hc_value)\n</code></pre>"},{"location":"metrics/g_relevance/#notes","title":"Notes","text":"<ul> <li>The function uses the <code>GnosticsCharacteristics</code> class from the Machine Gnostics library.</li> <li>The ratio \\(R = y_{\\text{true}} / y_{\\text{pred}}\\) is used to compute the gnostic characteristics.</li> <li>The result is normalized by the number of samples.</li> <li>Use <code>case='i'</code> for relevance and <code>case='j'</code> for irrelevance, depending on your analysis needs.</li> </ul>"},{"location":"metrics/gmmfe/","title":"gmmfe: Geometric Mean of Model Fit Error (GMMFE) Metric","text":"<p>The <code>gmmfe</code> function computes the Geometric Mean of Model Fit Error (GMMFE), a robust metric for evaluating the average relative error between observed data and model predictions on a logarithmic scale. GMMFE is especially useful for datasets with a wide range of values or when the data is multiplicative in nature.</p>"},{"location":"metrics/gmmfe/#overview","title":"Overview","text":"<p>GMMFE quantifies the average multiplicative error between the true and predicted values, making it less sensitive to outliers and scale differences than classical metrics. It is one of the three core criteria (alongside RobR2 and DivI) for evaluating model performance in the Machine Gnostics framework.</p> <p>Mathematically, GMMFE is defined as:</p> \\[ \\text{GMMFE} = \\exp\\left( \\frac{1}{N} \\sum_{i=1}^N \\left| \\log\\left(\\frac{y_i}{\\hat{y}_i}\\right) \\right| \\right) \\] <p>where:</p> <ul> <li>\\(y_i\\) is the observed value,</li> <li>\\(\\hat{y}_i\\) is the fitted (predicted) value,</li> <li>\\(N\\) is the number of data points.</li> </ul> <p>A lower GMMFE indicates a better fit, as it means the geometric mean of the relative errors is smaller.</p>"},{"location":"metrics/gmmfe/#interpretation","title":"Interpretation","text":"<ul> <li>Lower GMMFE: Indicates smaller average multiplicative errors and a better model fit.</li> <li>Higher GMMFE: Indicates larger average multiplicative errors and a poorer fit.</li> </ul> <p>GMMFE is particularly valuable when comparing models across datasets with different scales or when the error distribution is multiplicative.</p>"},{"location":"metrics/gmmfe/#parameters","title":"Parameters","text":"Parameter Type Description <code>y</code> np.ndarray Observed data (ground truth). 1D array of numerical values. <code>y_fit</code> np.ndarray Fitted data (model predictions). 1D array, same shape as <code>y</code>."},{"location":"metrics/gmmfe/#returns","title":"Returns","text":"<ul> <li>float   The computed Geometric Mean of Model Fit Error (GMMFE) value.</li> </ul>"},{"location":"metrics/gmmfe/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y</code> and <code>y_fit</code> do not have the same shape.</li> <li>If <code>y</code> or <code>y_fit</code> are not 1D arrays.</li> </ul>"},{"location":"metrics/gmmfe/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.metrics import gmmfe\n\ny = np.array([1.0, 2.0, 3.0, 4.0])\ny_fit = np.array([1.1, 1.9, 3.2, 3.8])\nresult = gmmfe(y, y_fit)\nprint(result)  # Output: 0.06666666666666667\n</code></pre>"},{"location":"metrics/gmmfe/#notes","title":"Notes","text":"<ul> <li>GMMFE is calculated using the weighted geometric mean of the relative errors.</li> <li>It is robust to outliers and scale differences, making it suitable for a wide range of regression problems.</li> <li>In the Machine Gnostics framework, GMMFE is used alongside RobR2 and DivI to provide a comprehensive evaluation of model performance.</li> <li>The overall evaluation metric can be computed as:</li> </ul> <p>$$   \\text{EvalMet} = \\frac{\\text{RobR2}}{\\text{GMMFE} \\cdot \\text{DivI}}   $$</p> <p>where a higher EvalMet indicates better model performance.</p>"},{"location":"metrics/mae/","title":"mean_absolute_error: Mean Absolute Error (MAE) Metric","text":"<p>The <code>mean_absolute_error</code> function computes the mean absolute error (MAE) between true and predicted values. MAE is a fundamental regression metric that measures the average magnitude of errors in a set of predictions, without considering their direction.</p>"},{"location":"metrics/mae/#overview","title":"Overview","text":"<p>Mean Absolute Error is defined as the average of the absolute differences between actual and predicted values.</p> <p>MAE is widely used in regression analysis to quantify how close predictions are to the actual outcomes. Lower MAE values indicate better model performance.</p>"},{"location":"metrics/mae/#parameters","title":"Parameters","text":"Parameter Type Description <code>y_true</code> array-like True values (targets). <code>y_pred</code> array-like Predicted values."},{"location":"metrics/mae/#returns","title":"Returns","text":"<ul> <li>float   The average absolute difference between actual and predicted values.</li> </ul>"},{"location":"metrics/mae/#raises","title":"Raises","text":"<ul> <li>TypeError   If <code>y_true</code> or <code>y_pred</code> are not array-like (list, tuple, or numpy array).</li> <li>ValueError   If inputs have mismatched shapes or are empty.</li> </ul>"},{"location":"metrics/mae/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import mean_absolute_error\n\n# Example 1: Using lists\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nprint(mean_absolute_error(y_true, y_pred))  # Output: 0.5\n\n# Example 2: Using numpy arrays\nimport numpy as np\ny_true = np.array([1, 2, 3])\ny_pred = np.array([1, 2, 2])\nprint(mean_absolute_error(y_true, y_pred))  # Output: 0.3333333333333333\n</code></pre>"},{"location":"metrics/mae/#notes","title":"Notes","text":"<ul> <li>The function supports input as lists, tuples, or numpy arrays.</li> <li>Both <code>y_true</code> and <code>y_pred</code> must have the same shape and must not be empty.</li> <li>MAE is robust to outliers but does not penalize large errors as strongly as mean squared error (MSE).</li> </ul>"},{"location":"metrics/mse/","title":"mean_squared_error: Mean Squared Error (MSE) Metric","text":"<p>The <code>mean_squared_error</code> function computes the mean squared error (MSE) between true and predicted values. MSE is a fundamental regression metric that measures the average of the squares of the errors\u2014that is, the average squared difference between the estimated values and the actual value.</p>"},{"location":"metrics/mse/#overview","title":"Overview","text":"<p>Mean Squared Error is defined as the average of the squared differences between actual and predicted values.</p> <p>MSE is widely used in regression analysis to quantify the accuracy of predictions. Lower MSE values indicate better model performance, while higher values indicate larger errors.</p>"},{"location":"metrics/mse/#parameters","title":"Parameters","text":"Parameter Type Description <code>y_true</code> array-like True values (targets). <code>y_pred</code> array-like Predicted values."},{"location":"metrics/mse/#returns","title":"Returns","text":"<ul> <li>float   The average of squared differences between actual and predicted values.</li> </ul>"},{"location":"metrics/mse/#raises","title":"Raises","text":"<ul> <li>TypeError   If <code>y_true</code> or <code>y_pred</code> are not array-like (list, tuple, or numpy array).</li> <li>ValueError   If inputs have mismatched shapes or are empty.</li> </ul>"},{"location":"metrics/mse/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import mean_squared_error\n\n# Example 1: Using lists\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nprint(mean_squared_error(y_true, y_pred))  # Output: 0.375\n\n# Example 2: Using numpy arrays\nimport numpy as np\ny_true = np.array([1, 2, 3])\ny_pred = np.array([1, 2, 2])\nprint(mean_squared_error(y_true, y_pred))  # Output: 0.3333333333333333\n</code></pre>"},{"location":"metrics/mse/#notes","title":"Notes","text":"<ul> <li>The function supports input as lists, tuples, or numpy arrays.</li> <li>Both <code>y_true</code> and <code>y_pred</code> must have the same shape and must not be empty.</li> <li>MSE penalizes larger errors more than MAE (mean absolute error), making it sensitive to outliers.</li> </ul>"},{"location":"metrics/precision/","title":"precision_score: Classification Precision Metric","text":"<p>The <code>precision_score</code> function computes the precision of classification models, supporting both binary and multiclass settings. Precision measures the proportion of positive identifications that were actually correct, making it a key metric for evaluating classifiers, especially when the cost of false positives is high.</p>"},{"location":"metrics/precision/#overview","title":"Overview","text":"<p>Precision is defined as the ratio of true positives (TP) to the sum of true positives and false positives (FP).</p> <p>This metric is especially important in scenarios where false positives are more costly than false negatives (e.g., spam detection, medical diagnosis).</p>"},{"location":"metrics/precision/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y_true</code> array-like or pandas Series \u2014 Ground truth (correct) target values. Shape: (n_samples,) <code>y_pred</code> array-like or pandas Series \u2014 Estimated target values as returned by a classifier. Shape: (n_samples,) <code>average</code> {'binary', 'micro', 'macro', 'weighted', None} 'binary' Determines the type of averaging performed on the data. See below for details. <code>labels</code> array-like or None None List of labels to include. If None, uses sorted unique labels from y_true and y_pred."},{"location":"metrics/precision/#averaging-options","title":"Averaging Options","text":"<ul> <li>'binary': Only report results for the positive class (default for binary classification).</li> <li>'micro': Calculate metrics globally by counting the total true positives, false negatives, and false positives.</li> <li>'macro': Calculate metrics for each label, and find their unweighted mean.</li> <li>'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label).</li> <li>None: Return the precision for each class as an array.</li> </ul>"},{"location":"metrics/precision/#returns","title":"Returns","text":"<ul> <li>precision: <code>float</code> or <code>array of floats</code>   Precision score(s). Returns a float if <code>average</code> is not None, otherwise returns an array of precision values for each class.</li> </ul>"},{"location":"metrics/precision/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y_true</code> or <code>y_pred</code> is a pandas DataFrame (must select a column).</li> <li>If the shapes of <code>y_true</code> and <code>y_pred</code> do not match.</li> <li>If <code>average='binary'</code> but the problem is not binary classification.</li> <li>If <code>average</code> is not a recognized option.</li> </ul>"},{"location":"metrics/precision/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import precision_score\n\n# Example 1: Macro-averaged precision for multiclass\ny_true = [0, 1, 2, 2, 0]\ny_pred = [0, 0, 2, 2, 0]\nprint(precision_score(y_true, y_pred, average='macro'))  # Output: 0.8333333333333333\n\n# Example 2: Binary precision with pandas Series\nimport pandas as pd\ndf = pd.DataFrame({'true': [1, 0, 1], 'pred': [1, 1, 1]})\nprint(precision_score(df['true'], df['pred'], average='binary'))  # Output: 0.6666666666666666\n</code></pre>"},{"location":"metrics/precision/#notes","title":"Notes","text":"<ul> <li>The function supports input as numpy arrays, lists, or pandas Series.</li> <li>If you pass a pandas DataFrame, you must select a column (e.g., <code>df['col']</code>), not the whole DataFrame.</li> <li>For binary classification, by convention, the second label is treated as the positive class.</li> <li>For imbalanced datasets, consider using <code>average='weighted'</code> to account for class support.</li> </ul>"},{"location":"metrics/r2_score/","title":"robr2: Robust R-squared (RobR2) Metric","text":"<p>The <code>robr2</code> function computes the Robust R-squared (RobR2) value for evaluating the goodness of fit between observed data and model predictions. Unlike the classical R-squared metric, RobR2 is robust to outliers and incorporates sample weights, making it ideal for noisy or irregular datasets.</p>"},{"location":"metrics/r2_score/#overview","title":"Overview","text":"<p>Robust R-squared (RobR2) measures the proportion of variance in the observed data explained by the fitted data, while reducing sensitivity to outliers. This is achieved by using a weighted formulation, which allows for more reliable model evaluation in real-world scenarios where data may not be perfectly clean.</p>"},{"location":"metrics/r2_score/#formula","title":"Formula","text":"\\[ \\text{RobR2} = 1 - \\frac{\\sum_i w_i (e_i - \\bar{e})^2}{\\sum_i w_i (y_i - \\bar{y})^2} \\] <p>Where:</p> <ul> <li>\\(e_i = y_i - \\hat{y}_i\\) (residuals)</li> <li>\\(\\bar{e}\\) = weighted mean of residuals</li> <li>\\(\\bar{y}\\) = weighted mean of observed data</li> <li>\\(w_i\\) = weight for each data point</li> </ul> <p>If weights are not provided, equal weights are assumed.</p>"},{"location":"metrics/r2_score/#parameters","title":"Parameters","text":"Parameter Type Description <code>y</code> np.ndarray Observed data (ground truth). 1D array of numerical values. <code>y_fit</code> np.ndarray Fitted data (model predictions). 1D array, same shape as <code>y</code>. <code>w</code> np.ndarray or None Optional weights for data points. 1D array, same shape as <code>y</code>. If None, equal weights are used."},{"location":"metrics/r2_score/#returns","title":"Returns","text":"<ul> <li>float   The computed Robust R-squared (RobR2) value. Ranges from 0 (no explanatory power) to 1 (perfect fit).</li> </ul>"},{"location":"metrics/r2_score/#raises","title":"Raises","text":"<ul> <li>ValueError</li> <li>If <code>y</code> and <code>y_fit</code> do not have the same shape.</li> <li>If <code>w</code> is provided and does not have the same shape as <code>y</code>.</li> <li>If <code>y</code> or <code>y_fit</code> are not 1D arrays.</li> </ul>"},{"location":"metrics/r2_score/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.metrics import robr2\n\ny = np.array([1.0, 2.0, 3.0, 4.0])\ny_fit = np.array([1.1, 1.9, 3.2, 3.8])\nw = np.array([1.0, 1.0, 1.0, 1.0])\n\nresult = robr2(y, y_fit, w)\nprint(result)  # Example output: 0.98\n</code></pre>"},{"location":"metrics/r2_score/#comparison-with-classical-r-squared","title":"Comparison with Classical R-squared","text":"<ul> <li>Classical R-squared: Assumes equal weights and is sensitive to outliers.</li> <li>RobR2: Incorporates weights and is robust to outliers, making it more reliable for datasets with irregularities or noise.</li> </ul>"},{"location":"metrics/r2_score/#references","title":"References","text":"<ul> <li>Kovanic P., Humber M.B (2015) The Economics of Information - Mathematical Gnostics for Data Analysis, Chapter 19</li> </ul>"},{"location":"metrics/r2_score/#notes","title":"Notes","text":"<ul> <li>If weights are not provided, the metric defaults to equal weighting for all data points.</li> <li>RobR2 is particularly useful for robust regression and model evaluation in the presence of outliers.</li> </ul>"},{"location":"metrics/recall/","title":"recall_score: Classification Recall Metric","text":"<p>The <code>recall_score</code> function computes the recall of classification models, supporting both binary and multiclass settings. Recall measures the proportion of actual positives that were correctly identified, making it a key metric for evaluating classifiers, especially when the cost of false negatives is high.</p>"},{"location":"metrics/recall/#overview","title":"Overview","text":"<p>Recall is defined as the ratio of true positives (TP) to the sum of true positives and false negatives (FN).</p> <p>This metric is especially important in scenarios where false negatives are more costly than false positives (e.g., disease screening, fraud detection).</p>"},{"location":"metrics/recall/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>y_true</code> array-like or pandas Series \u2014 Ground truth (correct) target values. Shape: (n_samples,) <code>y_pred</code> array-like or pandas Series \u2014 Estimated target values as returned by a classifier. Shape: (n_samples,) <code>average</code> {'binary', 'micro', 'macro', 'weighted', None} 'binary' Determines the type of averaging performed on the data. See below for details. <code>labels</code> array-like or None None List of labels to include. If None, uses sorted unique labels from y_true and y_pred."},{"location":"metrics/recall/#averaging-options","title":"Averaging Options","text":"<ul> <li>'binary': Only report results for the positive class (default for binary classification).</li> <li>'micro': Calculate metrics globally by counting the total true positives, false negatives, and false positives.</li> <li>'macro': Calculate metrics for each label, and find their unweighted mean.</li> <li>'weighted': Calculate metrics for each label, and find their average weighted by support (the number of true instances for each label).</li> <li>None: Return the recall for each class as an array.</li> </ul>"},{"location":"metrics/recall/#returns","title":"Returns","text":"<ul> <li>recall: <code>float</code> or <code>array of floats</code>   Recall score(s). Returns a float if <code>average</code> is not None, otherwise returns an array of recall values for each class.</li> </ul>"},{"location":"metrics/recall/#raises","title":"Raises","text":"<ul> <li>ValueError </li> <li>If <code>y_true</code> or <code>y_pred</code> is a pandas DataFrame (must select a column).</li> <li>If the shapes of <code>y_true</code> and <code>y_pred</code> do not match.</li> <li>If <code>average='binary'</code> but the problem is not binary classification.</li> <li>If <code>average</code> is not a recognized option.</li> </ul>"},{"location":"metrics/recall/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import recall_score\n\n# Example 1: Macro-averaged recall for multiclass\ny_true = [0, 1, 2, 2, 0]\ny_pred = [0, 0, 2, 2, 0]\nprint(recall_score(y_true, y_pred, average='macro'))  # Output: 0.8333333333333333\n\n# Example 2: Binary recall with pandas Series\nimport pandas as pd\ndf = pd.DataFrame({'true': [1, 0, 1], 'pred': [1, 1, 1]})\nprint(recall_score(df['true'], df['pred'], average='binary'))  # Output: 1.0\n</code></pre>"},{"location":"metrics/recall/#notes","title":"Notes","text":"<ul> <li>The function supports input as numpy arrays, lists, or pandas Series.</li> <li>If you pass a pandas DataFrame, you must select a column (e.g., <code>df['col']</code>), not the whole DataFrame.</li> <li>For binary classification, by convention, the second label is treated as the positive class.</li> <li>For imbalanced datasets, consider using <code>average='weighted'</code> to account for class support.</li> </ul>"},{"location":"metrics/rmse/","title":"root_mean_squared_error: Root Mean Squared Error (RMSE) Metric","text":"<p>The <code>root_mean_squared_error</code> function computes the Root Mean Squared Error (RMSE) between true and predicted values. RMSE is a widely used regression metric that measures the square root of the average of the squared differences between predicted and actual values.</p>"},{"location":"metrics/rmse/#overview","title":"Overview","text":"<p>Root Mean Squared Error is defined as the square root of the mean squared error.</p> <p>RMSE provides an interpretable measure of prediction error in the same units as the target variable. Lower RMSE values indicate better model performance.</p>"},{"location":"metrics/rmse/#parameters","title":"Parameters","text":"Parameter Type Description <code>y_true</code> array-like True values (targets). <code>y_pred</code> array-like Predicted values."},{"location":"metrics/rmse/#returns","title":"Returns","text":"<ul> <li>float   The square root of the average of squared errors between actual and predicted values.</li> </ul>"},{"location":"metrics/rmse/#raises","title":"Raises","text":"<ul> <li>TypeError   If <code>y_true</code> or <code>y_pred</code> are not array-like (list, tuple, or numpy array).</li> <li>ValueError   If inputs have mismatched shapes or are empty.</li> </ul>"},{"location":"metrics/rmse/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.metrics import root_mean_squared_error\n\n# Example 1: Using lists\ny_true = [3, -0.5, 2, 7]\ny_pred = [2.5, 0.0, 2, 8]\nprint(root_mean_squared_error(y_true, y_pred))  # Output: 0.6123724356957945\n\n# Example 2: Using numpy arrays\nimport numpy as np\ny_true = np.array([1, 2, 3])\ny_pred = np.array([1, 2, 2])\nprint(root_mean_squared_error(y_true, y_pred))  # Output: 0.5773502691896257\n</code></pre>"},{"location":"metrics/rmse/#notes","title":"Notes","text":"<ul> <li>The function supports input as lists, tuples, or numpy arrays.</li> <li>Both <code>y_true</code> and <code>y_pred</code> must have the same shape and must not be empty.</li> <li>RMSE is sensitive to outliers due to the squaring of errors.</li> <li>RMSE is in the same units as the target variable, making it easy to interpret.</li> </ul>"},{"location":"mg/architecture/","title":"Machine Gnostics Architecture","text":"<p>This diagram presents the conceptual architecture of the Machine Gnostics paradigm. Unlike traditional machine learning rooted in statistical theory, this new approach is built on the foundation of Mathematical Gnostics (MG)\u2014a finite, deterministic, and physically inspired framework.</p> <p></p>"},{"location":"mg/architecture/#1-data","title":"1. DATA","text":"<p>The foundation of Machine Gnostics is DATA, interpreted differently from statistical frameworks:</p> <ul> <li>Each data point is a real event with individual importance and uncertainty.</li> <li>No reliance on large sample assumptions or population-level abstractions.</li> <li>Adheres to the principle: \u201cLet the data speak for themselves.\u201d</li> </ul>"},{"location":"mg/architecture/#2-mathematical-gnostics","title":"2. Mathematical Gnostics","text":"<p>This is the theoretical base of the system. It replaces the assumptions of probability with deterministic modeling:</p> <ul> <li>Uses Riemannian geometry, Einsteinian relativity, vector bi-algebra, and thermodynamics.</li> <li>Models uncertainty at the level of individual events, not populations.</li> <li>Establishes a finite theory for finite data, with robust treatment of variability.</li> </ul>"},{"location":"mg/architecture/#3-magcal-mathematical-gnostics-calculations","title":"3. MAGCAL (Mathematical Gnostics Calculations)","text":"<p>MAGCAL is the computational engine that enables gnostic inference:</p> <ul> <li>Performs deterministic, non-statistical calculations.</li> <li>Enables robust modeling using gnostic algebra and error geometry.</li> <li>Resilient to outliers, corrupted data, and distributional shifts.</li> </ul>"},{"location":"mg/architecture/#4-models-metrics-magnet","title":"4. Models | Metrics | Magnet","text":"<p>This layer maps to familiar components of ML pipelines but with MG-specific logic:</p> <ul> <li>Models: Developed on the principles of Mathematical Gnostics.</li> <li>Metrics: Evaluate using gnostic loss functions and event-level error propagation.</li> <li>Magnet: A novel neural architecture based on Mathematical Gnostics</li> </ul>"},{"location":"mg/architecture/#5-mlflow-integration","title":"5. mlflow Integration","text":"<p>Despite its theoretical novelty, Machine Gnostics fits smoothly into modern ML workflows:</p> <ul> <li>mlflow provides tracking, model registry, and reproducibility.</li> <li>Ensures that experiments and deployments align with standard ML practices.</li> </ul>"},{"location":"mg/architecture/#6-machine-gnostics-integration-layer-for-machine-learning","title":"6. Machine Gnostics (Integration Layer for Machine Learning)","text":"<p>This layer unifies all components into a working system:</p> <ul> <li>MAGCAL is a Mathematical Gnostics based engine.</li> <li>Functions as a complete ML framework based on a deterministic, finite, and algebraic paradigm.</li> <li>Enables seamless data-to-model pipelines rooted in the principles of Mathematical Gnostics.</li> </ul>"},{"location":"mg/architecture/#summary","title":"Summary","text":"<p>Quick Understanding</p> Traditional ML (Statistics) Machine Gnostics Based on probability theory Based on deterministic finite theory Relies on large datasets Works directly with small datasets Uses averages and distributions Uses individual error and event modeling Rooted in Euclidean geometry Rooted in Riemannian geometry &amp; physics Vulnerable to outliers Robust to real-world irregularities"},{"location":"mg/architecture/#references","title":"References","text":"<p>Machine Gnostics is not just an alternative\u2014it is a new foundation for AI, capable of rational, robust, and interpretable data modeling.</p>"},{"location":"mg/examples/","title":"Examples \u2013 Machine Gnostics","text":"<p>Explore practical examples and Jupyter notebooks demonstrating the use of Machine Gnostics for various machine learning tasks. Each example includes code, explanations, and links to downloadable notebooks.</p>"},{"location":"mg/examples/#example-notebooks","title":"Example Notebooks","text":"<ol> <li> <p>Small Data Regression \u2013 Linear Regression A simple linear regression example using a small dataset to illustrate the basics of model fitting and evaluation.</p> </li> <li> <p>Wine Quality: Multidimensional Linear Regression Regression on the wine quality dataset with multiple input features (X), showcasing how to handle multivariate data using linear regression.</p> </li> <li> <p>Small Data Polynomial Regression Polynomial regression on a small dataset, demonstrating how to fit and evaluate nonlinear relationships.</p> </li> <li> <p>Wine Quality: Multidimensional Polynomial Regression Polynomial regression applied to the wine quality dataset with multiple features, highlighting advanced regression techniques.</p> </li> <li> <p>Basic Binary Logistic Regression A straightforward binary classification example using logistic regression, including model training and evaluation.</p> </li> <li> <p>Logistic Regression with MLflow Integration An end-to-end example of logistic regression with experiment tracking and reproducibility using MLflow.</p> </li> </ol>"},{"location":"mg/examples/#access-the-notebooks","title":"Access the Notebooks","text":"<p>You can download or view the Jupyter notebooks for each example from the examples directory in the repository.</p> <p>Examples</p> <p>More details on the Machine Gnostics Foundation fine here</p>"},{"location":"mg/foundation/","title":"Foundations of Mathematical Gnostics","text":"<p>Mathematical Gnostics (MG) offers a fundamentally different approach to data analysis and uncertainty compared to traditional mathematical statistics. Understanding these differences is crucial for users of the Machine Gnostics library, as it shapes the philosophy, algorithms, and practical outcomes of gnostic-based data analysis.</p>"},{"location":"mg/foundation/#key-differences-between-statistics-and-gnostics","title":"Key Differences Between Statistics and Gnostics","text":""},{"location":"mg/foundation/#1-focus-on-the-individual-event","title":"1. Focus on the Individual Event","text":"<ul> <li>Statistics: Traditional statistics investigates the regularities and properties of large collections of uncertain events, relying on the Law of Large Numbers and the Central Limit Theorem. The theory is built for infinite or very large sample sizes, and results for finite datasets are often extrapolated from these infinite models.</li> <li>Gnostics:   MG concentrates on the uncertainty of a single event. It builds mathematical and physical models that directly address finite (even small) collections of uncertain events. This approach is more natural for real-world scenarios, where data is always finite.</li> </ul>"},{"location":"mg/foundation/#2-treatment-of-data-and-uncertainty","title":"2. Treatment of Data and Uncertainty","text":"<ul> <li>Statistics: Assumes the existence of a mean and standard deviation for an underlying probability distribution. Data is often treated as samples from an idealized random process, and analysis is based on population-level properties.</li> <li>Gnostics:   Treats each data point as an image of a real, existing event governed by the laws of nature. MG respects the actual values of the data, following the principle: \u201cLet data speak for themselves.\u201d The weight or importance of each data item is determined by its own individual error, not by its class or family.</li> </ul>"},{"location":"mg/foundation/#3-mathematical-and-physical-foundations","title":"3. Mathematical and Physical Foundations","text":"<ul> <li>Statistics: Relies primarily on Euclidean geometry and Newtonian mechanics, with mathematical theory of measure as its foundation.</li> <li>Gnostics:   Utilizes Riemannian geometry and Einstein\u2019s relativistic mechanics, along with vector bi-algebra and thermodynamics. MG also introduces quantification theory as a foundational measurement theory.</li> </ul>"},{"location":"mg/foundation/#4-aggregation-and-analysis","title":"4. Aggregation and Analysis","text":"<ul> <li>Statistics: Aggregates observed data additively, focusing on population-level summaries.</li> <li>Gnostics:   Suggests that additive aggregation should be applied to the parameters of the Ideal Gnostic Cycle, not directly to the observed data.</li> </ul>"},{"location":"mg/foundation/#scientific-bases-a-comparative-diagram","title":"Scientific Bases: A Comparative Diagram","text":"<p>Figure: The scientific foundations of statistics (left) and gnostics (right) span mathematics, physics, geometry, and measurement theory, but differ fundamentally in their approach and underlying principles. [Pavel Kovanic, Mathematical Gnostics (2023)]</p>"},{"location":"mg/foundation/#approaches-to-data-uncertainty","title":"Approaches to Data Uncertainty","text":"<p>Figure: Statistics builds its theory for infinite sample sizes and extrapolates results for finite datasets. Gnostics, in contrast, constructs its theory directly for finite (even single) events, providing a more natural fit for real-world data. [Pavel Kovanic, Mathematical Gnostics (2023)]</p>"},{"location":"mg/foundation/#paradigm-shift-from-statistics-to-gnostics","title":"Paradigm Shift: From Statistics to Gnostics","text":"<p>Mathematical gnostics represents a paradigm shift in how we approach data variability and analysis:</p> <ul> <li>Statistics is rooted in the behavior of large numbers and infinite limits, often requiring extrapolation to address finite datasets.</li> <li>Gnostics is designed for the finite world, modeling uncertainty at the level of individual events and small datasets.</li> </ul> <p>This shift requires a new way of thinking, much like moving from Newtonian to Einsteinian physics. While statistics is easily demonstrated with simple experiments (like coin tosses), the power of gnostics is revealed through its algorithms and their performance on real-world, finite data.</p>"},{"location":"mg/foundation/#principles-of-the-gnostic-paradigm","title":"Principles of the Gnostic Paradigm","text":"<ol> <li>Concentration on Individual Events: MG focuses on the regularities and uncertainty of individual events, not just large populations.</li> <li>Respect for Data Values: Data is taken as it is, with each value carrying its own information and uncertainty.</li> <li>Use of Advanced Geometry and Mechanics: MG employs Riemannian geometry and relativistic mechanics, providing a richer mathematical framework for modeling uncertainty.</li> <li>Individual Error Weighting:    The importance of each data point is determined by its own error, not by group-level properties.</li> </ol>"},{"location":"mg/foundation/#why-adopt-the-gnostic-approach","title":"Why Adopt the Gnostic Approach?","text":"<ul> <li>Natural Fit for Finite Data: Real-world data is always finite. MG provides tools and theory that are directly applicable without relying on extrapolation from infinite models.</li> <li>Robustness: By focusing on individual data points and their uncertainties, MG offers greater resilience to outliers and corrupted data.</li> <li>Paradigm-Changing Power:   MG overcomes many limitations of traditional statistics, especially in cases where statistical assumptions break down.</li> </ul>"},{"location":"mg/foundation/#further-reading","title":"Further Reading","text":"<p>For a deeper dive into the foundations and applications of mathematical gnostics, see:</p> <ul> <li>Pavel Kovanic, Mathematical Gnostics (2023)</li> <li>Pavel Kovanic &amp; M.B. Humber, The Economics of Information: Mathematical Gnostics for Data Analysis (2015)</li> </ul> <p>Mathematical Gnostics is a new paradigm for data analysis\u2014one that respects the individuality of data, leverages advanced mathematics, and is designed for the finite, real world.</p>"},{"location":"mg/mg_arguments/","title":"Main Arguments and Concepts in Machine Gnostics ML Models","text":"<p>This document provides definitions and explanations for the main arguments and variables used in Machine Gnostics machine learning and deep learning models. Understanding these concepts will help users grasp the unique characteristics of the Machine Gnostics library, which is based on the non-statistical paradigm of Mathematical Gnostics.</p>"},{"location":"mg/mg_arguments/#core-concepts","title":"Core Concepts","text":"<ul> <li> <p>Machine Gnostics   A machine learning and deep learning library founded on Mathematical Gnostics, a non-statistical paradigm for data analysis.</p> </li> <li> <p>Mathematical Gnostics   An alternative to traditional statistical methods, focusing on the quantification and estimation of uncertainty in data.</p> </li> </ul>"},{"location":"mg/mg_arguments/#key-arguments-and-gnostic-characteristics","title":"Key Arguments and Gnostic Characteristics","text":""},{"location":"mg/mg_arguments/#1-gnostic-characteristics","title":"1. Gnostic Characteristics","text":"<p>These are the fundamental variables used to describe data in the gnostic framework. They are divided into two main spaces:</p> <ul> <li>Quantifying Space (Q-space, j):   Describes the variability and irrelevance in the data.</li> <li>Estimating Space (E-space, i):   Describes the estimation of variability and relevance.</li> </ul>"},{"location":"mg/mg_arguments/#quantifying-characteristics","title":"Quantifying Characteristics","text":"<ul> <li> <p>fj: Quantifying data variability   Measures the variability present in the data.</p> </li> <li> <p>hj: Quantifying irrelevance   Measures the irrelevance or error due to variability.</p> </li> </ul>"},{"location":"mg/mg_arguments/#estimating-characteristics","title":"Estimating Characteristics","text":"<ul> <li> <p>fi: Estimating data variability   Provides an estimation of the data's variability.</p> </li> <li> <p>hi: Estimating relevance   Provides an estimation of the data's relevance.</p> </li> </ul> <p>All four variables (\\( f_j, h_j, f_i, h_i \\)) are called gnostic characteristics.</p>"},{"location":"mg/mg_arguments/#2-probability-arguments","title":"2. Probability Arguments","text":"<ul> <li> <p>pi: Estimating probability   Probability estimate in the context of the gnostic model.</p> </li> <li> <p>pj: Quantifying probability   Quantifies the probability based on the quantifying characteristics.</p> </li> </ul>"},{"location":"mg/mg_arguments/#3-information","title":"3. Information","text":"<ul> <li> <p>Ii: Estimating information   Information estimate for the data.</p> </li> <li> <p>Ij: Quantifying information   Quantifies the information content.</p> </li> </ul>"},{"location":"mg/mg_arguments/#4-entropy","title":"4. Entropy","text":"<ul> <li> <p>ei: Estimating entropy   Entropy estimate for the data.</p> </li> <li> <p>ej: Quantifying entropy   Quantifies the entropy content.</p> </li> <li> <p>re: Residual entropy   The remaining entropy after estimation, representing the difference between quantification and estimation entropy.</p> </li> </ul>"},{"location":"mg/mg_arguments/#5-loss-functions","title":"5. Loss Functions","text":"<ul> <li>Hc loss: Gnostic mean relevance loss   A loss function based on gnostic relevance, where \\( c \\) can be \\( i \\) or \\( j \\).</li> </ul>"},{"location":"mg/mg_arguments/#further-reading","title":"Further reading","text":"<p>For more detailed mathematical background, see the foundational texts on Mathematical Gnostics and the documentation of the Machine Gnostics library.</p>"},{"location":"mg/principles/","title":"Principles of Advanced Data Analysis in Machine Gnostics","text":"<p>Machine Gnostics is grounded in the philosophy of Mathematical Gnostics, which emphasizes extracting the maximum information from data while respecting its objectivity and inherent structure. These principles are especially relevant for modern machine learning and data science, where robust, data-driven insights are crucial.</p> <p>Below are the core principles of advanced data analysis as practiced in Machine Gnostics, adapted for practical use in machine learning and data science:</p>"},{"location":"mg/principles/#key-principles","title":"Key Principles","text":""},{"location":"mg/principles/#1-respect-the-objectivity-of-data","title":"1. Respect the Objectivity of Data","text":"<ul> <li>Avoid imposing unjustified models: Do not force data into a priori statistical models or distributions without evidence.</li> <li>Do not trim or discard outliers without justification: Outliers may contain valuable information about the system or process.</li> <li>Acknowledge non-homogeneity: Recognize and address the presence of outliers and sample non-homogeneity rather than ignoring them.</li> <li>Use proper aggregation: Aggregate data in ways that respect the underlying structure and axioms of gnostic theory.</li> <li>Respect data finiteness: Do not treat finite samples as if they were infinite populations.</li> </ul>"},{"location":"mg/principles/#2-make-use-of-all-available-data","title":"2. Make Use of All Available Data","text":"<ul> <li>Include censored and incomplete data: Do not ignore data just because it is partially observed.</li> <li>Weight outliers and inliers appropriately: Assign justified weights to suspected outliers and inliers (noise), rather than excluding them outright.</li> <li>Exclude data only with evidence: Remove data points only if their impact is negligible or their origin is invalid.</li> <li>Consider side effects: Be aware of and account for side effects caused by the processes generating the data.</li> </ul>"},{"location":"mg/principles/#3-let-the-data-decide","title":"3. Let the Data Decide","text":"<ul> <li>Allow data to determine its own structure: Let the data reveal its group membership, homogeneity, bounds, and metric space.</li> <li>Data-driven uncertainty: Evaluate uncertainty using the data\u2019s own properties, not just statistical assumptions.</li> <li>Interdependence and distribution: Let the data inform you about its interdependence, distribution, and density functions.</li> <li>Separate uncertainty from variability: Distinguish between uncertainty and true variability in the data.</li> </ul>"},{"location":"mg/principles/#4-individualized-weighting","title":"4. Individualized Weighting","text":"<ul> <li>Assign weights at the data point level: Each data item should be weighted based on its own value, not just the sample it belongs to.</li> </ul>"},{"location":"mg/principles/#5-use-statistical-methods-judiciously","title":"5. Use Statistical Methods Judiciously","text":"<ul> <li>Justify statistical assumptions: Only use statistical methods when their assumptions are met by the data.</li> <li>Embrace non-statistical methods: When statistical assumptions fail, use robust, non-statistical approaches.</li> </ul>"},{"location":"mg/principles/#6-prefer-robust-methods","title":"6. Prefer Robust Methods","text":"<ul> <li>Robust estimation: Use robust estimation and identification methods over non-robust ones, especially in the presence of outliers or non-normal data.</li> <li>Choose the right robustness: Select the type of robustness (inner/outer) appropriate for your task.</li> </ul>"},{"location":"mg/principles/#7-prefer-distributions-over-point-estimates","title":"7. Prefer Distributions Over Point Estimates","text":"<ul> <li>Use distribution functions: Where possible, use full distributions rather than single-point estimates for data characteristics.</li> </ul>"},{"location":"mg/principles/#8-ensure-comparability","title":"8. Ensure Comparability","text":"<ul> <li>Compare like with like: Only compare objects or samples that behave according to the same model.</li> </ul>"},{"location":"mg/principles/#9-seek-explanations-not-excuses","title":"9. Seek Explanations, Not Excuses","text":"<ul> <li>Don\u2019t blame randomness: Investigate and explain uncertainty using data and available information, rather than attributing everything to randomness.</li> </ul>"},{"location":"mg/principles/#10-apply-realistic-and-theoretically-sound-criteria","title":"10. Apply Realistic and Theoretically Sound Criteria","text":"<ul> <li>Optimize using information/entropy: Use information-theoretic criteria for optimization and evaluation.</li> <li>Follow optimal data transformation paths: Respect theoretically proven optimal methods for data transformation and estimation.</li> </ul>"},{"location":"mg/principles/#11-maintain-an-open-and-critical-mindset","title":"11. Maintain an Open and Critical Mindset","text":"<ul> <li>Avoid methodological conservatism: Be open to new methods and approaches.</li> <li>Challenge expectations: Do not insist on preconceived outcomes or reject unexpected results without further analysis.</li> <li>Prioritize thoughtful analysis: The best data treatment may require more effort and deeper thinking.</li> </ul>"},{"location":"mg/principles/#why-these-principles-matter-in-machine-learning-data-science","title":"Why These Principles Matter in Machine Learning &amp; Data Science","text":"<ul> <li>Robustness: Machine Gnostics methods are designed to be robust to outliers, noise, and non-standard data distributions, making them ideal for real-world data.</li> <li>Data-Driven: The approach lets the data guide the analysis, reducing bias from unjustified assumptions.</li> <li>Comprehensive Use of Data: No data is wasted\u2014every point is considered for its potential information value.</li> <li>Transparency: By letting the data decide, results are more interpretable and trustworthy.</li> </ul>"},{"location":"mg/principles/#summary-for-new-users","title":"Summary for New Users","text":"<ul> <li>Don\u2019t force your data into ill-fitting models.</li> <li>Use all your data, including outliers and incomplete points, with justified weighting.</li> <li>Let the data reveal its own structure, uncertainty, and relationships.</li> <li>Prefer robust, information-theoretic methods when possible.</li> <li>Be open-minded and critical\u2014let the data, not your expectations, drive your analysis.</li> </ul> <p>Machine Gnostics provides a principled, robust, and data-centric foundation for advanced data analysis in machine learning and data science.</p>"},{"location":"mg/principles/#references","title":"References","text":""},{"location":"models/cls/log_reg/","title":"LogisticRegressor: Robust Logistic Regression with Machine Gnostics","text":"<p>LogisticRegressor is a robust and flexible binary classification model built on the Machine Gnostics framework. It is designed to handle outliers, heavy-tailed distributions, and non-Gaussian noise, making it suitable for real-world data challenges. The model supports polynomial feature expansion, robust weighting, early stopping, and seamless MLflow integration for experiment tracking and deployment.</p>"},{"location":"models/cls/log_reg/#overview","title":"Overview","text":"<p>Machine Gnostics LogisticRegressor brings deterministic, event-level modeling to binary classification. By leveraging gnostic algebra and geometry, it provides robust, interpretable, and reproducible results, even in challenging scenarios.</p> <p>Highlights:</p> <ul> <li>Outlier Robustness: Gnostic weighting reduces the impact of noisy or corrupted samples.</li> <li>Polynomial Feature Expansion: Configurable degree for nonlinear decision boundaries.</li> <li>Flexible Probability Output: Choose between gnostic-based or standard sigmoid probabilities.</li> <li>Early Stopping: Efficient training via monitoring of loss and entropy.</li> <li>MLflow Integration: Supports experiment tracking and deployment.</li> <li>Model Persistence: Save and load models easily with joblib.</li> </ul>"},{"location":"models/cls/log_reg/#key-features","title":"Key Features","text":"<ul> <li>Robust to outliers and non-Gaussian noise</li> <li>Polynomial feature expansion (configurable degree)</li> <li>Flexible probability output: gnostic or sigmoid</li> <li>Customizable data scaling (auto or manual)</li> <li>Early stopping based on residual entropy or log loss</li> <li>Full training history tracking (loss, entropy, coefficients, weights)</li> <li>MLflow integration for model tracking and deployment</li> <li>Save and load model using joblib</li> </ul>"},{"location":"models/cls/log_reg/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>degree</code> int 1 Degree of the polynomial for feature expansion (1 = linear). <code>max_iter</code> int 100 Maximum number of training iterations. <code>tol</code> float 1e-3 Convergence threshold for loss or coefficient changes. <code>scale</code> {'auto', float} 'auto' Scaling mode for gnostic transformation. <code>early_stopping</code> bool True Enables early stopping based on convergence criteria. <code>history</code> bool True Records training history at each iteration. <code>proba</code> {'gnostic','sigmoid'} 'gnostic' Probability output mode. <code>verbose</code> bool False Prints progress and debug information. <code>data_form</code> str 'a' Input data form: <code>'a'</code> (additive), <code>'m'</code> (multiplicative)."},{"location":"models/cls/log_reg/#attributes","title":"Attributes","text":"<ul> <li>coefficients: <code>ndarray</code>   Final learned polynomial regression coefficients.</li> <li>weights: <code>ndarray</code>   Final sample weights after convergence.</li> <li>_history: <code>list of dict</code>   Training history, including loss, entropy, coefficients, and weights at each iteration.</li> </ul>"},{"location":"models/cls/log_reg/#methods","title":"Methods","text":""},{"location":"models/cls/log_reg/#fitx-y","title":"<code>fit(X, y)</code>","text":"<p>Fits the model to training data using polynomial expansion and robust loss minimization.</p> <ul> <li>X: array-like, pandas.DataFrame, or numpy.ndarray of shape <code>(n_samples, n_features)</code>   Training input samples.</li> <li>y: array-like or numpy.ndarray of shape <code>(n_samples,)</code>   Target binary labels (0 or 1).</li> </ul> <p>Returns: <code>self</code> (for method chaining)</p>"},{"location":"models/cls/log_reg/#predictx","title":"<code>predict(X)</code>","text":"<p>Predicts class labels (0 or 1) for new input samples using the trained model.</p> <ul> <li>X: array-like, pandas.DataFrame, or numpy.ndarray of shape <code>(n_samples, n_features)</code>   Input samples for prediction.</li> </ul> <p>Returns: <code>y_pred</code>: numpy.ndarray of shape <code>(n_samples,)</code> Predicted binary class labels.</p>"},{"location":"models/cls/log_reg/#predict_probax","title":"<code>predict_proba(X)</code>","text":"<p>Predicts probabilities for new input samples using the trained model.</p> <ul> <li>X: array-like, pandas.DataFrame, or numpy.ndarray of shape <code>(n_samples, n_features)</code>   Input samples for probability prediction.</li> </ul> <p>Returns: <code>proba</code>: numpy.ndarray of shape <code>(n_samples,)</code> Predicted probabilities for the positive class (label 1).</p>"},{"location":"models/cls/log_reg/#save_modelpath","title":"<code>save_model(path)</code>","text":"<p>Saves the trained model to disk using joblib.</p> <ul> <li>path: str   Directory path to save the model.</li> </ul>"},{"location":"models/cls/log_reg/#load_modelpath","title":"<code>load_model(path)</code>","text":"<p>Loads a previously saved model from disk.</p> <ul> <li>path: str   Directory path where the model is saved.</li> </ul> <p>Returns: Instance of <code>LogisticRegressor</code> with loaded parameters.</p>"},{"location":"models/cls/log_reg/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.models import LogisticRegressor\n\n# Initialize the model\nmodel = LogisticRegressor(degree=2, proba='gnostic', verbose=True)\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Predict class labels\ny_pred = model.predict(X_test)\n\n# Predict probabilities\ny_proba = model.predict_proba(X_test)\n\n# Access coefficients and weights\nprint(\"Coefficients:\", model.coefficients)\nprint(\"Weights:\", model.weights)\n\n# Save the model\nmodel.save_model(\"my_logreg_model\")\n\n# Load the model\nloaded = LogisticRegressor.load_model(\"my_logreg_model\")\ny_pred2 = loaded.predict(X_test)\n</code></pre>"},{"location":"models/cls/log_reg/#training-history","title":"Training History","text":"<p>If <code>history=True</code>, the model records training history at each iteration, accessible via <code>model._history</code>. Each entry contains:</p> <ul> <li><code>iteration</code>: Iteration number</li> <li><code>loss</code>: Loss value (gnostic or log loss)</li> <li><code>entropy</code>: Residual entropy value</li> <li><code>coefficients</code>: Regression coefficients at this iteration</li> <li><code>weights</code>: Sample weights at this iteration</li> </ul> <p>This enables detailed analysis and visualization of the training process.</p>"},{"location":"models/cls/log_reg/#example-notebooks","title":"Example Notebooks","text":"<ul> <li>Example 1</li> <li>Example 2</li> </ul>"},{"location":"models/cls/log_reg/#notes","title":"Notes","text":"<ul> <li>The model supports numpy arrays, pandas DataFrames, and pyspark DataFrames as input.</li> <li>For best results, ensure input features are appropriately scaled and encoded.</li> <li>Supports integration with MLflow for experiment tracking and deployment.</li> <li>For more information, visit: https://machinegnostics.info/</li> </ul> <p>Author: Nirmal Parmar Date: 2025-05-01</p>"},{"location":"models/magnet/magnet/","title":"Magnet: Machine Gnostic Neural Network","text":"<p>Magnet is the Machine Gnostic (Neural) Network, a novel architecture inspired by the principles of Mathematical Gnostics (MG). Unlike traditional neural networks that rely on probabilistic backpropagation and statistical learning, Magnet is built on a deterministic, finite, and algebraic foundation.</p>"},{"location":"models/magnet/magnet/#key-features","title":"Key Features","text":"<ul> <li>Deterministic Learning: No reliance on probability or randomness; all computations are finite and reproducible.</li> <li>Event-Level Modeling: Handles uncertainty and error at the level of individual data events, not populations.</li> <li>Algebraic Inference: Utilizes gnostic algebra and error geometry for robust, interpretable learning.</li> <li>Resilient Architecture: Designed to be robust against outliers, corrupted data, and distributional shifts.</li> </ul> <p>Status</p> <p>Magnet is currently under development. Coming soon: Detailed documentation, architecture diagrams, and implementation guides.</p> <p>Stay tuned for updates as we bring the next generation of neural networks to Machine Gnostics!</p> <p>Machine Gnostics - Machine Gnostics Library Copyright (C) 2025  Machine Gnostics Team</p>"},{"location":"models/reg/lin_reg/","title":"LinearRegressor: Robust Linear Regression with Machine Gnostics","text":"<p>LinearRegressor is a robust linear regression model built on the Machine Gnostics framework. Unlike traditional statistical models that rely on probabilistic assumptions, this model uses algebraic and geometric structures to provide deterministic, resilient, and interpretable regression for real-world data.</p>"},{"location":"models/reg/lin_reg/#overview","title":"Overview","text":"<p>The Machine Gnostics LinearRegressor is designed for robust regression tasks, especially where data may contain outliers, noise, or non-Gaussian distributions. It leverages the core principles of Mathematical Gnostics (MG) to deliver reliable results even in challenging scenarios.</p> <ul> <li>Deterministic &amp; Finite: No randomness or probability; all computations are reproducible.</li> <li>Event-Level Modeling: Handles uncertainty and error at the level of individual data events.</li> <li>Algebraic Inference: Utilizes gnostic algebra and error geometry for robust learning.</li> <li>Resilient: Designed to be robust against outliers, corrupted data, and distributional shifts.</li> <li>Flexible: Supports numpy arrays, pandas DataFrames, and pyspark DataFrames.</li> <li>mlflow Integration: For experiment tracking and deployment.</li> <li>Easy Model Persistence: Save and load models with joblib.</li> </ul>"},{"location":"models/reg/lin_reg/#key-features","title":"Key Features","text":"<ul> <li>Fits a linear regression model</li> <li>Robust to outliers and non-Gaussian noise</li> <li>Iterative optimization with early stopping and convergence tolerance</li> <li>Adaptive sample weighting using gnostic loss</li> <li>Training history tracking for analysis and visualization</li> <li>Customizable loss functions and scaling strategies</li> <li>Compatible with numpy arrays for input/output</li> </ul>"},{"location":"models/reg/lin_reg/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>scale</code> {'auto', int, float} 'auto' Scaling method or value for input features. <code>max_iter</code> int 100 Maximum number of optimization iterations. <code>tol</code> float 1e-3 Tolerance for convergence. <code>mg_loss</code> str 'hi' Gnostic loss function to use (<code>'hi'</code>, <code>'fi'</code>, etc.). <code>early_stopping</code> bool True Whether to stop early if convergence is detected. <code>verbose</code> bool False If True, prints progress and diagnostics during fitting. <code>data_form</code> str 'a' Internal data representation format. <code>gnostic_characteristics</code> bool True If True, computes and records gnostic properties (fi, hi, etc.). <code>history</code> bool True If True, records the optimization history for analysis."},{"location":"models/reg/lin_reg/#attributes","title":"Attributes","text":"<ul> <li>coefficients: <code>np.ndarray</code>Fitted linear regression coefficients.</li> <li>weights: <code>np.ndarray</code>Final sample weights after robust fitting.</li> <li>params: <code>list of dict</code>Parameter snapshots (loss, weights, gnostic properties) at each iteration.</li> <li>_history: <code>list</code>Internal optimization history (if enabled).</li> <li>degree, max_iter, tol, mg_loss, early_stopping, verbose, scale, data_form, gnostic_characteristics:   Configuration parameters as set at initialization.</li> </ul>"},{"location":"models/reg/lin_reg/#methods","title":"Methods","text":""},{"location":"models/reg/lin_reg/#fitx-y","title":"<code>fit(X, y)</code>","text":"<p>Fits the linear regressor to input features <code>X</code> and targets <code>y</code> using robust, gnostic loss minimization. Iteratively optimizes coefficients and sample weights, optionally recording history.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>Input features.</li> <li>y: <code>np.ndarray</code>, shape <code>(n_samples,)</code>   Target values.</li> </ul> <p>Returns: <code>self</code> (fitted model instance)</p>"},{"location":"models/reg/lin_reg/#predictx","title":"<code>predict(X)</code>","text":"<p>Predicts target values for new input features using the trained model.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>   Input features for prediction.</li> </ul> <p>Returns: <code>y_pred</code>: <code>np.ndarray</code>, shape <code>(n_samples,)</code> Predicted target values.</p>"},{"location":"models/reg/lin_reg/#scorex-y-casei","title":"<code>score(X, y, case='i')</code>","text":"<p>Computes the robust (gnostic) R\u00b2 score for the linear regressor model.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>Input features for scoring.</li> <li>y: <code>np.ndarray</code>, shape <code>(n_samples,)</code>True target values.</li> <li>case: <code>str</code>, default <code>'i'</code>   Specifies the case or variant of the R\u00b2 score to compute.</li> </ul> <p>Returns: <code>score</code>: <code>float</code> Robust R\u00b2 score of the model on the provided data.</p>"},{"location":"models/reg/lin_reg/#save_modelpath","title":"<code>save_model(path)</code>","text":"<p>Saves the trained model to disk using joblib.</p> <ul> <li>path: str   Directory path to save the model.</li> </ul>"},{"location":"models/reg/lin_reg/#load_modelpath","title":"<code>load_model(path)</code>","text":"<p>Loads a previously saved model from disk.</p> <ul> <li>path: str   Directory path where the model is saved.</li> </ul> <p>Returns: Instance of <code>LogisticRegressor</code> with loaded parameters.</p>"},{"location":"models/reg/lin_reg/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.models.regression import LinearRegressor\n\n# Initialize the model\nmodel = LinearRegressor(max_iter=100, mg_loss='hi', verbose=True)\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Score\nr2 = model.score(X_test, y_test)\nprint(f\"Robust R2 score: {r2}\")\n\n# Access coefficients and weights\nprint(\"Coefficients:\", model.coefficients)\nprint(\"Weights:\", model.weights)\n</code></pre>"},{"location":"models/reg/lin_reg/#training-history","title":"Training History","text":"<p>If <code>history=True</code>, the model records detailed training history at each iteration, accessible via <code>model.params</code> and <code>model._history</code>. Each entry contains:</p> <ul> <li><code>iteration</code>: Iteration number</li> <li><code>loss</code>: Gnostic loss value</li> <li><code>coefficients</code>: Regression coefficients at this iteration</li> <li><code>rentropy</code>: Rentropy value (residual entropy)</li> <li><code>weights</code>: Sample weights at this iteration</li> <li><code>gnostic_characteristics</code>: (if enabled) fi, hi, etc.</li> </ul> <p>This enables in-depth analysis and visualization of the training process.</p>"},{"location":"models/reg/lin_reg/#example-notebooks","title":"Example Notebooks","text":"<ul> <li>Example 1</li> <li>Example 2</li> </ul>"},{"location":"models/reg/lin_reg/#notes","title":"Notes","text":"<ul> <li>The model is robust to outliers and suitable for datasets with non-Gaussian noise.</li> <li>Supports integration with mlflow for experiment tracking and deployment.</li> <li>For more information, visit: https://machinegnostics.info/</li> </ul> <p>Author: Nirmal Parmar  Date: 2025-05-01</p>"},{"location":"models/reg/poly_reg/","title":"PolynomialRegressor: Robust Polynomial Regression with Machine Gnostics","text":"<p>The <code>PolynomialRegressor</code> is a robust polynomial regression model built on the principles of Mathematical Gnostics. It is designed to provide deterministic, interpretable, and resilient regression in the presence of outliers, noise, and non-Gaussian data distributions. Unlike traditional statistical models, this regressor leverages algebraic and geometric concepts from Mathematical Gnostics, focusing on event-level modeling and robust loss minimization.</p>"},{"location":"models/reg/poly_reg/#overview","title":"Overview","text":"<ul> <li>Robust to Outliers: Uses gnostic loss functions and adaptive weights to minimize the influence of outliers and corrupted samples.</li> <li>Polynomial Feature Expansion: Supports configurable polynomial degrees for flexible modeling.</li> <li>Iterative Optimization: Employs iterative fitting with early stopping and convergence checks.</li> <li>Custom Gnostic Loss: Minimizes a user-selected gnostic loss (<code>'hi'</code>, <code>'hj'</code>, etc.) for event-level robustness.</li> <li>Detailed Training History: Optionally records loss, weights, entropy, and gnostic characteristics at each iteration.</li> <li>Easy Integration: Compatible with numpy arrays and supports model persistence.</li> </ul>"},{"location":"models/reg/poly_reg/#key-features","title":"Key Features","text":"<ul> <li>Robust regression using gnostic loss functions</li> <li>Flexible polynomial degree (linear and higher-order)</li> <li>Adaptive sample weighting</li> <li>Early stopping and convergence tolerance</li> <li>Training history tracking for analysis and visualization</li> <li>Handles non-Gaussian noise and outliers</li> <li>Compatible with numpy arrays</li> </ul>"},{"location":"models/reg/poly_reg/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>degree</code> int 2 Degree of the polynomial to fit. <code>scale</code> {'auto', int, float} 'auto' Scaling method or value for input features. <code>max_iter</code> int 100 Maximum number of optimization iterations. <code>tol</code> float 1e-3 Tolerance for convergence. <code>mg_loss</code> str 'hi' Gnostic loss function to use (<code>'hi'</code>, <code>'fi'</code>, etc.). <code>early_stopping</code> bool True Whether to stop early if convergence is detected. <code>verbose</code> bool False If True, prints progress and diagnostics during fitting. <code>data_form</code> str 'a' Internal data representation format. <code>gnostic_characteristics</code> bool True If True, computes and records gnostic properties (fi, hi, etc.). <code>history</code> bool True If True, records the optimization history for analysis."},{"location":"models/reg/poly_reg/#attributes","title":"Attributes","text":"<ul> <li>coefficients: <code>np.ndarray</code>   Fitted polynomial regression coefficients.</li> <li>weights: <code>np.ndarray</code>   Final sample weights after robust fitting.</li> <li>params: <code>list of dict</code>   Parameter snapshots (loss, weights, gnostic properties) at each iteration.</li> <li>_history: <code>list</code>   Internal optimization history (if enabled).</li> <li>degree, max_iter, tol, mg_loss, early_stopping, verbose, scale, data_form, gnostic_characteristics:   Configuration parameters as set at initialization.</li> </ul>"},{"location":"models/reg/poly_reg/#methods","title":"Methods","text":""},{"location":"models/reg/poly_reg/#fitx-y","title":"<code>fit(X, y)</code>","text":"<p>Fits the polynomial regressor to input features <code>X</code> and targets <code>y</code> using robust, gnostic loss minimization. Iteratively optimizes coefficients and sample weights, optionally recording history.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>   Input features.</li> <li>y: <code>np.ndarray</code>, shape <code>(n_samples,)</code>   Target values.</li> </ul> <p>Returns: <code>self</code> (fitted model instance)</p>"},{"location":"models/reg/poly_reg/#predictx","title":"<code>predict(X)</code>","text":"<p>Predicts target values for new input features using the trained model.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>   Input features for prediction.</li> </ul> <p>Returns: <code>y_pred</code>: <code>np.ndarray</code>, shape <code>(n_samples,)</code> Predicted target values.</p>"},{"location":"models/reg/poly_reg/#scorex-y-casei","title":"<code>score(X, y, case='i')</code>","text":"<p>Computes the robust (gnostic) R\u00b2 score for the polynomial regressor model.</p> <ul> <li>X: <code>np.ndarray</code>, shape <code>(n_samples, n_features)</code>   Input features for scoring.</li> <li>y: <code>np.ndarray</code>, shape <code>(n_samples,)</code>   True target values.</li> <li>case: <code>str</code>, default <code>'i'</code>   Specifies the case or variant of the R\u00b2 score to compute.</li> </ul> <p>Returns: <code>score</code>: <code>float</code> Robust R\u00b2 score of the model on the provided data.</p>"},{"location":"models/reg/poly_reg/#save_modelpath","title":"<code>save_model(path)</code>","text":"<p>Saves the trained model to disk using joblib.</p> <ul> <li>path: str   Directory path to save the model.</li> </ul>"},{"location":"models/reg/poly_reg/#load_modelpath","title":"<code>load_model(path)</code>","text":"<p>Loads a previously saved model from disk.</p> <ul> <li>path: str   Directory path where the model is saved.</li> </ul> <p>Returns: Instance of <code>LogisticRegressor</code> with loaded parameters.</p>"},{"location":"models/reg/poly_reg/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.models.regression import PolynomialRegressor\n\n# Initialize the model\nmodel = PolynomialRegressor(degree=2, mg_loss='hi', verbose=True)\n\n# Fit the model\nmodel.fit(X_train, y_train)\n\n# Predict\ny_pred = model.predict(X_test)\n\n# Score\nr2 = model.score(X_test, y_test)\nprint(f'Robust R2 score: {r2}')\n\n# Access coefficients and weights\nprint(\"Coefficients:\", model.coefficients)\nprint(\"Weights:\", model.weights)\n</code></pre>"},{"location":"models/reg/poly_reg/#training-history","title":"Training History","text":"<p>If <code>history=True</code>, the model records detailed training history at each iteration, accessible via <code>model.params</code> and <code>model._history</code>. Each entry contains:</p> <ul> <li><code>iteration</code>: Iteration number</li> <li><code>loss</code>: Gnostic loss value</li> <li><code>coefficients</code>: Regression coefficients at this iteration</li> <li><code>rentropy</code>: Rentropy value (residual entropy)</li> <li><code>weights</code>: Sample weights at this iteration</li> <li><code>gnostic_characteristics</code>: (if enabled) fi, hi, etc.</li> </ul> <p>This enables in-depth analysis and visualization of the training process.</p>"},{"location":"models/reg/poly_reg/#example-notebooks","title":"Example Notebooks","text":"<ul> <li>Example 1</li> <li>Example 2</li> </ul>"},{"location":"models/reg/poly_reg/#notes","title":"Notes","text":"<ul> <li>The model is robust to outliers and suitable for datasets with non-Gaussian noise.</li> <li>Implements advanced machine learning techniques based on Mathematical Gnostics.</li> <li>For more information, visit: https://machinegnostics.info/</li> </ul> <p>Author: Nirmal Parmar Date: 2025-05-01</p>"},{"location":"models/sup/cross_val/","title":"CrossValidator: Custom k-Fold Cross-Validation","text":"<p>The <code>CrossValidator</code> class provides a simple, flexible implementation of k-fold cross-validation for evaluating machine learning models. It is designed to work with any model that implements <code>fit(X, y)</code> and <code>predict(X)</code> methods, and supports custom scoring functions for regression or classification tasks.</p>"},{"location":"models/sup/cross_val/#overview","title":"Overview","text":"<p>Cross-validation is a robust technique for assessing the generalization performance of machine learning models. The <code>CrossValidator</code> class splits your dataset into <code>k</code> folds, trains the model on <code>k-1</code> folds, and evaluates it on the remaining fold, repeating this process for each fold. The results are aggregated to provide a reliable estimate of model performance.</p>"},{"location":"models/sup/cross_val/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>model</code> object \u2014 A machine learning model with <code>fit(X, y)</code> and <code>predict(X)</code> methods. <code>X</code> array-like \u2014 Feature matrix of shape <code>(n_samples, n_features)</code>. <code>y</code> array-like \u2014 Target labels of shape <code>(n_samples,)</code>. <code>k</code> int 5 Number of folds for cross-validation. <code>shuffle</code> bool True Whether to shuffle the dataset before splitting into folds. <code>random_seed</code> int/None None Seed for reproducible shuffling (ignored if <code>shuffle=False</code>)."},{"location":"models/sup/cross_val/#attributes","title":"Attributes","text":"<ul> <li>folds: <code>list of tuple</code>   List of <code>(train_indices, test_indices)</code> for each fold.</li> </ul>"},{"location":"models/sup/cross_val/#methods","title":"Methods","text":""},{"location":"models/sup/cross_val/#split","title":"<code>split()</code>","text":"<p>Splits the dataset into <code>k</code> folds.</p> <ul> <li>Returns:   <code>folds</code>: list of tuple   Each tuple contains <code>(train_indices, test_indices)</code> for a fold.</li> </ul>"},{"location":"models/sup/cross_val/#evaluatescoring_func","title":"<code>evaluate(scoring_func)</code>","text":"<p>Performs k-fold cross-validation and returns evaluation scores.</p> <ul> <li>Parameters:<code>scoring_func</code>: callableA function that takes <code>y_true</code> and <code>y_pred</code> and returns a numeric score (e.g., <code>mean_squared_error</code>, <code>accuracy_score</code>).</li> <li>Returns:   <code>scores</code>: list of float   Evaluation scores for each fold.</li> </ul>"},{"location":"models/sup/cross_val/#example-usage","title":"Example Usage","text":"<pre><code>from machinegnostics.models import CrossValidator, LinearRegressor\nfrom machinegnostics.metircs import mean_squared_error\nimport numpy as np\n\n# Generate random data\nX = np.random.rand(100, 10)\ny = np.random.rand(100)\n\n# Initialize model and cross-validator\nmodel = LinearRegressor()\ncv = CrossValidator(model, X, y, k=5, shuffle=True, random_seed=42)\n\n# Evaluate using mean squared error\nscores = cv.evaluate(mean_squared_error)\nprint(\"Cross-Validation Scores:\", scores)\nprint(\"Mean Score:\", np.mean(scores))\n</code></pre>"},{"location":"models/sup/cross_val/#notes","title":"Notes","text":"<ul> <li>The model is re-initialized and trained from scratch for each fold.</li> <li>Supports any model with <code>fit</code> and <code>predict</code> methods.</li> <li>Works with any scoring function that accepts <code>y_true</code> and <code>y_pred</code>.</li> <li>Shuffling with a fixed <code>random_seed</code> ensures reproducible splits.</li> </ul> <p>Author: Nirmal Parmar Date: 2025-05-01</p>"},{"location":"models/sup/train_test_split/","title":"train_test_split: Random Train/Test Data Splitter","text":"<p>The <code>train_test_split</code> function provides a simple and flexible way to split your dataset into random training and testing subsets. It is compatible with numpy arrays and can also handle lists or tuples as input. This function is essential for evaluating machine learning models on unseen data and is a core utility in most ML workflows.</p>"},{"location":"models/sup/train_test_split/#overview","title":"Overview","text":"<p>Splitting your data into training and testing sets is a fundamental step in machine learning. The <code>train_test_split</code> function allows you to:</p> <ul> <li>Randomly partition your data into train and test sets.</li> <li>Specify the proportion or absolute number of test samples.</li> <li>Shuffle your data for unbiased splitting.</li> <li>Use a random seed for reproducibility.</li> <li>Split both features (<code>X</code>) and targets (<code>y</code>) in a consistent manner.</li> </ul>"},{"location":"models/sup/train_test_split/#parameters","title":"Parameters","text":"Parameter Type Default Description <code>X</code> array-like \u2014 Feature data to be split. Must be indexable and of consistent length. <code>y</code> array-like or None None Target data to be split alongside X. Must be same length as X. <code>test_size</code> float or int 0.25 If float, fraction of data for test set (0.0 &lt; test_size &lt; 1.0). If int, absolute number of test samples. <code>shuffle</code> bool True Whether to shuffle the data before splitting. <code>random_seed</code> int or None None Controls the shuffling for reproducibility."},{"location":"models/sup/train_test_split/#returns","title":"Returns","text":"<ul> <li> <p>X_train, X_test: <code>np.ndarray</code>   Train-test split of X.</p> </li> <li> <p>y_train, y_test: <code>np.ndarray</code> or <code>None</code>   Train-test split of y. If y is None, these will also be None.</p> </li> </ul>"},{"location":"models/sup/train_test_split/#raises","title":"Raises","text":"<ul> <li> <p>ValueError   If inputs are invalid or <code>test_size</code> is not appropriate.</p> </li> <li> <p>TypeError   If <code>test_size</code> is not a float or int.</p> </li> </ul>"},{"location":"models/sup/train_test_split/#example-usage","title":"Example Usage","text":"<pre><code>import numpy as np\nfrom machinegnostics.models import train_test_split\n\n# Create sample data\nX = np.arange(20).reshape(10, 2)\ny = np.arange(10)\n\n# Split into train and test sets\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.3, shuffle=True, random_seed=42\n)\n\nprint(\"X_train:\", X_train)\nprint(\"X_test:\", X_test)\nprint(\"y_train:\", y_train)\nprint(\"y_test:\", y_test)\n</code></pre>"},{"location":"models/sup/train_test_split/#notes","title":"Notes","text":"<ul> <li>If <code>y</code> is not provided, only <code>X</code> will be split and <code>y_train</code>, <code>y_test</code> will be <code>None</code>.</li> <li>If <code>test_size</code> is a float, it must be between 0.0 and 1.0 (exclusive).</li> <li>If <code>test_size</code> is an int, it must be between 1 and <code>len(X) - 1</code>.</li> <li>Setting <code>shuffle=False</code> will split the data in order, without randomization.</li> <li>Use <code>random_seed</code> for reproducible splits.</li> </ul> <p>Author: Nirmal Parmar Date: 2025-05-01</p>"},{"location":"ref/references/","title":"References","text":"<p>Machine Gnostics Publications</p> <p>Publications on Machine Gnostics will be available soon. This website is designed to provide the essential fundamentals to help you get started.</p> <p>Below is a curated list of key publications where the concept of Mathematical Gnostics is introduced, explained, and applied in research and practice.</p>"},{"location":"ref/references/#books","title":"Books","text":"<p> Kovanic, P.; Humber, M.B. The Economics of Information\u2014Mathematical Gnostics for Data Analysis. 2015. </p> <p> Kovanic, P. Mathematical Gnostics, 2023. DOI: 10.1201/9780429441196 </p>"},{"location":"ref/references/#research-papers","title":"Research Papers","text":"<p> Parmar, N.; Bendov\u00e1, M.; Wagner, Z., Heat capacity measurements by a Setaram \u03bcDSC3 evo microcalorimeter: Estimation of deviation in the measurement, advanced data analysis by mathematical gnostics, and prediction by the artificial neural network. J Therm Anal Calorim 150, 313\u2013325 (2025). https://doi.org/10.1007/s10973-024-13505-w </p> <p> Parmar, N.; Bendov\u00e1, M.; Wagner, Z.; P\u011bnkavov\u00e1, V.; Douihri, I.; Jacquemin, J., Carbon nanotube-based ionanofluids for efficient energy storage: Thermophysical properties\u2019 determination and advanced data analysis.  Industrial &amp; Engineering Chemistry Research 2021, 60 (20), 7714\u20137728. DOI: 10.1021/acs.iecr.0c06008 </p> <p> Parmar, N. et al., A study of changes in the heat capacity of carbon nanotube-based ionanofluids prepared from a series of imidazolium ionic liquids.  https://doi.org/10.1039/D2CP02110B </p> <p> Wagner, Z.; Bendov\u00e1, M.; Rotrekl, J.; Sykorova, A.; Canji, M.; Parmar, N., Density and sound velocity measurement by an Anton Paar DSA 5000 density meter: Precision and long-time stability.  J Mol Liq 329, 2021, 115547. ISSN 0167-7322. </p> <p> Wagner, Z.; Bendov\u00e1, M.; Rotrekl, J.; Parmar, N.; Koc\u0131, S.; Vrbka, P., Thermochemical properties of menthol and terpineol.  J Solution Chem 49, 1267\u20131278, 2020. </p>"}]}