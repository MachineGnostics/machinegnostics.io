{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Machine Gnostics","text":"<p>Welcome to Machine Gnostics, an innovative Python library designed to implement the principles of Machine Gnostics for robust data analysis, modeling, and inference. Unlike traditional statistical approaches that depend heavily on probabilistic assumptions, Machine Gnostics harnesses deterministic algebraic and geometric structures. This unique foundation enables the library to deliver exceptional resilience against outliers, noise, and corrupted data, making it a powerful tool for challenging real-world scenarios.</p> <p>Machine Gnostics is an open-source initiative that seeks to redefine the mathematical underpinnings of machine learning. While most conventional ML libraries are grounded in probabilistic and statistical frameworks, Machine Gnostics explores alternative paradigms\u2014drawing from deterministic algebra, information theory, and geometric methods. This approach opens new avenues for building robust, interpretable, and reliable analysis tools that can withstand the limitations of traditional models.</p> <p>Note</p> <p>As a pioneering project, Machine Gnostics invites users to adopt a fresh perspective and develop a new understanding of machine learning. The library is currently in its infancy, and as such, some features may require refinement and fixes. We are actively working to expand its capabilities, with new models and methods planned for the near future. Community support and collaboration are essential to realizing Machine Gnostics\u2019 full potential. Together, let\u2019s build a new AI grounded in a rational and resilient paradigm.</p> <p> </p>"},{"location":"#overview","title":"Overview","text":"<p>Machine Gnostics offers a comprehensive suite of tools for robust analysis:</p> <ul> <li>Robust Regression Models \u2013 Polynomial regression models with gnostic-based weighting for optimal resilience to outliers  </li> <li>Gnostic Metrics \u2013 Alternative evaluation metrics that provide more reliable performance assessment in the presence of corrupted data  </li> <li>Mathematical Gnostics Calculations \u2013 Core implementations of gnostic statistics including robust measures of central tendency, dispersion, and correlation  </li> </ul>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>\ud83d\udee1\ufe0f Exceptional Outlier Resistance \u2013 Automatically detects and downweights anomalous observations without manual intervention  </li> <li>\ud83d\udd0d Information-Theoretic Foundation \u2013 Based on rigorous mathematical principles rather than probabilistic assumptions  </li> <li>\ud83d\udd27 Drop-in Replacements \u2013 Use gnostic alternatives to common statistical measures like mean, median, correlation  </li> <li>\ud83d\udcca MLflow Integration \u2013 Seamless model tracking, versioning, and deployment  </li> <li>\ud83e\uddea Scientifically Validated \u2013 Tested on real-world problems across multiple domains including thermodynamics, materials science, and engineering  </li> </ul>"},{"location":"#references","title":"References","text":"<p>Books</p> <ul> <li>Kovanic P., Humber M.B.: The Economics of Information-Mathematical Gnostics for Data Analysis, book 717 pp., 2015  </li> <li>Kovanic P., Mathematical Gnostics, 2023, DOI: 10.1201/9780429441196  </li> </ul> <p>Research Papers</p> <ul> <li>Parmar, N., Bendov\u00e1, M. &amp; Wagner, Z. Heat capacity measurements by a Setaram \u03bcDSC3 evo microcalorimeter: estimation of deviation in the measurement, advanced data analysis by mathematical gnostics, and prediction by the artificial neural network. J Therm Anal Calorim 150, 313\u2013325 (2025). https://doi.org/10.1007/s10973-024-13505-w </li> <li>Nirmal Parmar, Magdalena Bendov\u00e1, Zden\u011bk Wagner, V\u011bra P\u011bnkavov\u00e1, Ilias Douihri, and Johan Jacquemin, Carbon Nanotube-Based Ionanofluids for Efficient Energy Storage: Thermophysical Properties\u2019 Determination and Advanced Data Analysis, Industrial &amp; Engineering Chemistry Research 2021 60 (20), 7714-7728 DOI: 10.1021/acs.iecr.0c06008 </li> <li>Parmar, N. et. al, A study of changes in the heat capacity of carbon nanotube-based ionanofluids prepared from a series of imidazolium ionic liquids, https://doi.org/10.1039/D2CP02110B </li> <li>Zdenek Wagner, Magdalena Bendova, Jan Rotrekl, Adela Sykorova, Maja Canji, Nirmal Parmar, Density and sound velocity measurement by an Anton Paar DSA 5000 density meter: Precision and long-time stability, J Mol Liq, Volume 329, 2021, 115547, ISSN 0167-7322  </li> <li>Zdenek Wagner, Magdalena Bendova, Jan Rotrekl, Nirmal Parmar, Stanislav Koc\u0131 and Pavel Vrbka Thermochemical Properties of Menthol and Terpineol. J Solution Chem 49, 1267\u20131278, 2020  </li> </ul>"},{"location":"architecture/","title":"Machine Gnostics Architecture","text":"<p>This diagram presents the conceptual architecture of the Machine Gnostics paradigm. Unlike traditional machine learning rooted in statistical theory, this new approach is built on the foundation of Mathematical Gnostics (MG)\u2014a finite, deterministic, and physically inspired framework.</p> <p></p>"},{"location":"architecture/#1-data-base-layer","title":"1. DATA (Base Layer)","text":"<p>The foundation of Machine Gnostics is DATA, interpreted differently from statistical frameworks:</p> <ul> <li>Each data point is a real event with individual importance and uncertainty.</li> <li>No reliance on large sample assumptions or population-level abstractions.</li> <li>Adheres to the principle: \u201cLet the data speak for themselves.\u201d</li> </ul>"},{"location":"architecture/#2-mathematical-gnostics","title":"2. Mathematical Gnostics","text":"<p>This is the theoretical base of the system. It replaces the assumptions of probability with deterministic modeling:</p> <ul> <li>Uses Riemannian geometry, Einsteinian relativity, vector bi-algebra, and thermodynamics.</li> <li>Models uncertainty at the level of individual events, not populations.</li> <li>Establishes a finite theory for finite data, with robust treatment of variability.</li> </ul>"},{"location":"architecture/#3-magcal-mathematical-gnostics-calculations","title":"3. MAGCAL (Mathematical Gnostics Calculations)","text":"<p>MAGCAL is the computational engine that enables gnostic inference:</p> <ul> <li>Performs deterministic, non-statistical calculations.</li> <li>Enables robust modeling using gnostic algebra and error geometry.</li> <li>Resilient to outliers, corrupted data, and distributional shifts.</li> </ul>"},{"location":"architecture/#4-models-metrics-magnet","title":"4. Models | Metrics | Magnet","text":"<p>This layer maps to familiar components of ML pipelines but with MG-specific logic:</p> <ul> <li>Models: Trained using MAGCAL with finite-event inference.</li> <li>Metrics: Evaluate using gnostic loss functions and event-level error propagation.</li> <li>Magnet: A novel neural architecture based on Mathematical Gnostics, avoiding probabilistic backpropagation and inspired by algebraic learning.</li> </ul>"},{"location":"architecture/#5-mlflow-integration","title":"5. mlflow Integration","text":"<p>Despite its theoretical novelty, Machine Gnostics fits smoothly into modern ML workflows:</p> <ul> <li>mlflow provides tracking, model registry, and reproducibility.</li> <li>Ensures that experiments and deployments align with standard ML practices.</li> </ul>"},{"location":"architecture/#6-machine-gnostics-integration-layer","title":"6. Machine Gnostics (Integration Layer)","text":"<p>This layer unifies all components into a working system:</p> <ul> <li>Integrates MAGCAL, Magnet, and MG-based components.</li> <li>Functions as a complete ML framework based on a deterministic, finite, and algebraic paradigm.</li> <li>Enables seamless data-to-model pipelines rooted in the principles of Mathematical Gnostics.</li> </ul>"},{"location":"architecture/#summary","title":"Summary","text":"Traditional ML (Statistics) Machine Gnostics Based on probability theory Based on deterministic finite theory Relies on large datasets Works directly with small datasets Uses averages and distributions Uses individual error and event modeling Rooted in Euclidean geometry Rooted in Riemannian geometry &amp; physics Vulnerable to outliers Robust to real-world irregularities"},{"location":"architecture/#further-reading","title":"Further Reading","text":"<ul> <li>Pavel Kovanic, Mathematical Gnostics (2023)</li> <li>P. Kovanic &amp; M.B. Humber, The Economics of Information (2015)</li> </ul> <p>Machine Gnostics is not just an alternative\u2014it is a new foundation for AI, capable of rational, robust, and interpretable data modeling.</p>"},{"location":"contact/","title":"Contact","text":"<p>If you have any questions, suggestions, or issues related to Machine Gnostics, feel free to reach out. We welcome feedback from the community and are happy to assist you.</p> <p>Contact Person Dr. Nirmal Parmar \ud83d\udce7 machinegnostics@gmail.com</p> <p>We appreciate your interest in Machine Gnostics and look forward to collaborating with researchers, developers, and practitioners passionate about robust and interpretable machine learning.</p> <p>For issues or feature requests, please consider opening a ticket on our GitHub repository.</p>"},{"location":"foundation/","title":"Foundations of Mathematical Gnostics","text":"<p>Mathematical Gnostics (MG) offers a fundamentally different approach to data analysis and uncertainty compared to traditional mathematical statistics. Understanding these differences is crucial for users of the Machine Gnostics library, as it shapes the philosophy, algorithms, and practical outcomes of gnostic-based data analysis.</p>"},{"location":"foundation/#key-differences-between-statistics-and-gnostics","title":"Key Differences Between Statistics and Gnostics","text":""},{"location":"foundation/#1-focus-on-the-individual-event","title":"1. Focus on the Individual Event","text":"<ul> <li>Statistics: Traditional statistics investigates the regularities and properties of large collections of uncertain events, relying on the Law of Large Numbers and the Central Limit Theorem. The theory is built for infinite or very large sample sizes, and results for finite datasets are often extrapolated from these infinite models.</li> <li>Gnostics:   MG concentrates on the uncertainty of a single event. It builds mathematical and physical models that directly address finite (even small) collections of uncertain events. This approach is more natural for real-world scenarios, where data is always finite.</li> </ul>"},{"location":"foundation/#2-treatment-of-data-and-uncertainty","title":"2. Treatment of Data and Uncertainty","text":"<ul> <li>Statistics: Assumes the existence of a mean and standard deviation for an underlying probability distribution. Data is often treated as samples from an idealized random process, and analysis is based on population-level properties.</li> <li>Gnostics:   Treats each data point as an image of a real, existing event governed by the laws of nature. MG respects the actual values of the data, following the principle: \u201cLet data speak for themselves.\u201d The weight or importance of each data item is determined by its own individual error, not by its class or family.</li> </ul>"},{"location":"foundation/#3-mathematical-and-physical-foundations","title":"3. Mathematical and Physical Foundations","text":"<ul> <li>Statistics: Relies primarily on Euclidean geometry and Newtonian mechanics, with mathematical theory of measure as its foundation.</li> <li>Gnostics:   Utilizes Riemannian geometry and Einstein\u2019s relativistic mechanics, along with vector bi-algebra and thermodynamics. MG also introduces quantification theory as a foundational measurement theory.</li> </ul>"},{"location":"foundation/#4-aggregation-and-analysis","title":"4. Aggregation and Analysis","text":"<ul> <li>Statistics: Aggregates observed data additively, focusing on population-level summaries.</li> <li>Gnostics:   Suggests that additive aggregation should be applied to the parameters of the Ideal Gnostic Cycle, not directly to the observed data.</li> </ul>"},{"location":"foundation/#scientific-bases-a-comparative-diagram","title":"Scientific Bases: A Comparative Diagram","text":"<p>Figure: The scientific foundations of statistics (left) and gnostics (right) span mathematics, physics, geometry, and measurement theory, but differ fundamentally in their approach and underlying principles. [Pavel Kovanic, Mathematical Gnostics (2023)]</p>"},{"location":"foundation/#approaches-to-data-uncertainty","title":"Approaches to Data Uncertainty","text":"<p>Figure: Statistics builds its theory for infinite sample sizes and extrapolates results for finite datasets. Gnostics, in contrast, constructs its theory directly for finite (even single) events, providing a more natural fit for real-world data. [Pavel Kovanic, Mathematical Gnostics (2023)]</p>"},{"location":"foundation/#paradigm-shift-from-statistics-to-gnostics","title":"Paradigm Shift: From Statistics to Gnostics","text":"<p>Mathematical gnostics represents a paradigm shift in how we approach data variability and analysis:</p> <ul> <li>Statistics is rooted in the behavior of large numbers and infinite limits, often requiring extrapolation to address finite datasets.</li> <li>Gnostics is designed for the finite world, modeling uncertainty at the level of individual events and small datasets.</li> </ul> <p>This shift requires a new way of thinking, much like moving from Newtonian to Einsteinian physics. While statistics is easily demonstrated with simple experiments (like coin tosses), the power of gnostics is revealed through its algorithms and their performance on real-world, finite data.</p>"},{"location":"foundation/#principles-of-the-gnostic-paradigm","title":"Principles of the Gnostic Paradigm","text":"<ol> <li>Concentration on Individual Events: MG focuses on the regularities and uncertainty of individual events, not just large populations.</li> <li>Respect for Data Values: Data is taken as it is, with each value carrying its own information and uncertainty.</li> <li>Use of Advanced Geometry and Mechanics: MG employs Riemannian geometry and relativistic mechanics, providing a richer mathematical framework for modeling uncertainty.</li> <li>Individual Error Weighting:    The importance of each data point is determined by its own error, not by group-level properties.</li> </ol>"},{"location":"foundation/#why-adopt-the-gnostic-approach","title":"Why Adopt the Gnostic Approach?","text":"<ul> <li>Natural Fit for Finite Data: Real-world data is always finite. MG provides tools and theory that are directly applicable without relying on extrapolation from infinite models.</li> <li>Robustness: By focusing on individual data points and their uncertainties, MG offers greater resilience to outliers and corrupted data.</li> <li>Paradigm-Changing Power:   MG overcomes many limitations of traditional statistics, especially in cases where statistical assumptions break down.</li> </ul>"},{"location":"foundation/#further-reading","title":"Further Reading","text":"<p>For a deeper dive into the foundations and applications of mathematical gnostics, see:</p> <ul> <li>Pavel Kovanic, Mathematical Gnostics (2023)</li> <li>Pavel Kovanic &amp; M.B. Humber, The Economics of Information: Mathematical Gnostics for Data Analysis (2015)</li> </ul> <p>Mathematical Gnostics is a new paradigm for data analysis\u2014one that respects the individuality of data, leverages advanced mathematics, and is designed for the finite, real world.</p>"},{"location":"installation/","title":"Installation Guide","text":"<p>Machine Gnostics is distributed as a standard Python package and is designed for easy installation and integration into your data science workflow. The library has been tested on macOS with Python 3.11 and is fully compatible with standard data science libraries such as NumPy, pandas, and SciPy.</p>"},{"location":"installation/#1-create-a-python-virtual-environment","title":"1. Create a Python Virtual Environment","text":"<p>It is best practice to use a virtual environment to manage your project dependencies and avoid conflicts with other Python packages.</p> <pre><code># Create a new virtual environment named 'machine-gnostics-env'\npython3 -m venv machinegnostics-env\n\n# Activate the environment (macOS/Linux)\nsource machine-gnostics-env/bin/activate\n\n# (On Windows, use: machine-gnostics-env\\Scripts\\activate)\n</code></pre>"},{"location":"installation/#2-install-machine-gnostics","title":"2. Install Machine Gnostics","text":"<p>Install the Machine Gnostics library using pip:</p> <pre><code>pip install machinegnostics\n</code></pre> <p>This command will install Machine Gnostics and automatically resolve its dependencies.</p>"},{"location":"installation/#3-optional-install-standard-data-science-libraries","title":"3. (Optional) Install Standard Data Science Libraries","text":"<p>If you do not already have them, install the most common data science libraries:</p> <pre><code>pip install numpy pandas scipy\n</code></pre>"},{"location":"installation/#4-verify-installation","title":"4. Verify Installation","text":"<p>You can verify that Machine Gnostics and its dependencies are installed correctly by importing them in a Python session:</p> <pre><code>import machinegnostics\nimport numpy\n\nprint(\"All libraries imported successfully!\")\n</code></pre>"},{"location":"installation/#5-quick-usage-example","title":"5. Quick Usage Example","text":"<p>Machine Gnostics is designed to be as simple to use as other machine learning libraries. You can call its functions and classes directly after installation.</p> <pre><code>import machinegnostics as mg\nimport numpy as np\nfrom mg.models import RobustRegressor\n\n# Example data\nX = np.array([[1], [2], [3], [4]])\ny = np.array([2, 4, 6, 8])\n\n# Create and fit a robust polynomial regression model\nmodel = RobustRegressor(degree=1)\nmodel.fit(X, y)\n\n# Make predictions\ny_pred = model.predict(X)\n\nprint(\"Predictions:\", y_pred)\n</code></pre>"},{"location":"installation/#6-platform-and-environment","title":"6. Platform and Environment","text":"<ul> <li>Operating System: Tested on macOS (Apple Silicon and Intel)</li> <li>Python Version: 3.11 recommended</li> <li>Dependencies: Compatible with NumPy, pandas, SciPy, and other standard data science libraries</li> </ul>"},{"location":"installation/#7-troubleshooting","title":"7. Troubleshooting","text":"<ul> <li>zEnsure your virtual environment is activated before installing or running Machine Gnostics.</li> <li> <p>If you encounter issues, try upgrading pip:   <pre><code>pip install --upgrade pip\n</code></pre></p> </li> <li> <p>For further help, consult the official documentation or open an issue on the GitHub repository.</p> </li> </ul> <p>Machine Gnostics is designed for simplicity and reliability, making robust machine learning accessible for all Python users.</p>"},{"location":"usage/","title":"Usage Guide","text":"<p>This guide provides a comprehensive overview of how to use the Machine Gnostics library for robust data analysis and machine learning based on Machine Gnostics principles. Machine Gnostics offers robust regression models, gnostic metrics, and alternative statistical tools designed to be resilient to outliers and corrupted data.</p>"},{"location":"usage/#1-importing-machine-gnostics","title":"1. Importing Machine Gnostics","text":"<p>After installation, you can import Machine Gnostics and its modules in your Python scripts or notebooks:</p> <pre><code>import machinegnostics as mg\nfrom machinegnostics.models import RobustRegressor\nfrom machinegnostics.metrics import robr2, gmmfe, divI, evalMet, hc\nfrom machinegnostics.magcal import gmedian, gvariance, gautocovariance, gcorrelation, gcovariance\n</code></pre>"},{"location":"usage/#2-robust-regression","title":"2. Robust Regression","text":"<p>Machine Gnostics provides robust regression models that are less sensitive to outliers.</p> <p>Example: Using <code>RobustRegressor</code></p> <pre><code>from machinegnostics.models import RobustRegressor\n\n# X: feature matrix, y: target vector\nmodel = RobustRegressor()\nmodel.fit(X, y)\ny_pred = model.predict(X_test)\n</code></pre>"},{"location":"usage/#3-gnostic-metrics","title":"3. Gnostic Metrics","text":"<p>Evaluate your models with robust, gnostic metrics:</p> <pre><code>from machinegnostics.metrics import robr2, gmmfe\n\nscore = robr2(y_true, y_pred)\ngmmfe = gmmfe(y_true, y_pred)\nhc = hc(y_true, y_pred, case='i') # estimating case\n</code></pre> <p>Other available metrics:</p> <ul> <li><code>divI</code>: Divergence Index</li> <li><code>evalMet</code>: General evaluation metric</li> <li><code>hc</code>: Relavance of the given data samples</li> </ul>"},{"location":"usage/#4-gnostic-statistical-tools","title":"4. Gnostic Statistical Tools","text":"<p>Machine Gnostics includes robust alternatives to classical statistics:</p> <pre><code>gmed = gmedian(data)\ngmod = gmodulus(data)\ngvar = gvariance(data)\ngacov = gautocovariance(data1, data2)\ngcor = gcorrelation(data1, data2)\ngcov = gcovariance(data1, data2)\n</code></pre>"},{"location":"usage/#5-example-workflow","title":"5. Example Workflow","text":"<pre><code>import numpy as np\nfrom machinegnostics.models import RobustRegressor\nfrom machinegnostics.metrics import robr2\n\n# Generate synthetic data\nX = np.random.randn(100, 3)\ny = 2 * X[:, 0] - X[:, 1] + np.random.randn(100) * 0.5\n\n# Fit robust regression\nmodel = RobustRegressor()\nmodel.fit(X, y)\ny_pred = model.predict(X)\n\n# Evaluate\nscore = robr2(y, y_pred)\nprint(\"Robust R2:\", score)\n</code></pre>"},{"location":"usage/#6-troubleshooting","title":"6. Troubleshooting","text":"<ul> <li>ImportError: Ensure Machine Gnostics is installed and your <code>PYTHONPATH</code> includes the <code>src</code> directory.</li> <li>Unexpected Results: Check for outliers or corrupted data in your input.</li> </ul> <p>For further help, open an issue on GitHub or contact the maintainers.</p>"}]}